{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c72e251-2af0-4a2c-9472-eb4067514a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/VecRepV3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "path = os.path.abspath(\"../../VecRepV3\") \n",
    "sys.path.append(path)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6f07d21-f78f-47b0-9d7b-38fec8a29d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/miniconda3/envs/test/lib/python3.12/site-packages/_distutils_hack/__init__.py:53: UserWarning: Reliance on distutils from stdlib is deprecated. Users must rely on setuptools to provide the distutils module. Avoid importing distutils or import setuptools first, and avoid setting SETUPTOOLS_USE_DISTUTILS=stdlib. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, Sampler, random_split, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "from line_profiler import profile\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "\n",
    "import src.data_processing.BruteForceEstimator as bfEstimator\n",
    "import src.data_processing.ImageCalculations as imgcalc\n",
    "import src.visualization.ImagePlots as imgplt\n",
    "import src.helpers.ModelUtilities as models\n",
    "import src.data_processing.Utilities as utils\n",
    "import src.helpers.FilepathUtils as Futils\n",
    "import src.data_processing.EmbeddingFunctions as embedfunc\n",
    "\n",
    "from src.visualization import SamplingMethod, BFmethod\n",
    "from src.data_processing.SampleEstimator import SampleEstimator\n",
    "from functools import partial\n",
    "from learnable_polyphase_sampling.learn_poly_sampling.layers import get_logits_model, PolyphaseInvariantDown2D, LPS\n",
    "from learnable_polyphase_sampling.learn_poly_sampling.layers.polydown import set_pool\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07fd8a85-8c07-4a18-bd98-ed43fef5c1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:03:26,518 [INFO] Previous sample images loaded....\n",
      "2025-02-19 09:03:26,519 [INFO] Generating image product matrix....\n",
      "2025-02-19 09:03:26,721 [INFO] Generating embeddings....\n",
      "524\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ----------------------------------Image Input----------------------------------\n",
    "IMAGE_TYPES = [\"NbinMmax_ones\", \"Nbin\", \"triangles\", \"triangle_mean_subtracted\"]\n",
    "\n",
    "IMAGE_FILTERS = [\"unique\", \"Nmax_ones\", \"one_island\"]\n",
    "\n",
    "IMAGE_PRODUCT_TYPES = [\"ncc\", \"ncc_scaled\"]\n",
    "\n",
    "EMBEDDING_TYPES = [\"pencorr_D\"]\n",
    "\n",
    "dimensions = 512\n",
    "\n",
    "imageType = \"shapes_3_dims_6_3\" #6x6 triangle in 12x12 matrix shapes_3_dims_6_3\n",
    "filters = [\"unique\"]\n",
    "imageProductType = \"ncc_scaled_-1\"\n",
    "overwrite = {\"imgSet\": False, \"imgProd\": False, \"embedding\": False}\n",
    "weight = None\n",
    "embeddingType = f\"pencorr_{dimensions}\"\n",
    "k=5\n",
    "percentage = 0.41\n",
    "\n",
    "imageSet = utils.generate_filtered_image_set(imageType, filters, Futils.get_image_set_filepath(imageType, filters))\n",
    "imageSet = np.array(imageSet)\n",
    "\n",
    "sampleName = f\"{imageType} {filters} {percentage} sample\"\n",
    "\n",
    "sampleEstimator = SampleEstimator(sampleName=sampleName, embeddingType=embeddingType, imageProductType=imageProductType)\n",
    "\n",
    "testSample = np.array([img for img in imageSet if not np.any([np.array_equal(img, train_img) for train_img in sampleEstimator.trainingImageSet])])\n",
    "#brute force one more image for dimension 128 T-T\n",
    "testSample = np.append(testSample, [sampleEstimator.trainingImageSet[50]], axis=0)\n",
    "print(len(testSample))\n",
    "\n",
    "index1 = np.random.randint(len(testSample))\n",
    "index2 = np.random.randint(len(testSample))\n",
    "\n",
    "input1=testSample[index1]\n",
    "input2=testSample[index2]\n",
    "\n",
    "imgplt.plot_original_images(input1, input2, index1, index2)\n",
    "\n",
    "# ------------------------- Preprocessing Dataset ------------------------\n",
    "input_dataset = []\n",
    "for img in testSample:\n",
    "    img_tensor = torch.from_numpy(np.array(img, dtype=np.float64))\n",
    "    img_tensor = img_tensor.unsqueeze(0).unsqueeze(0).to(device).double()\n",
    "    input_dataset.append(img_tensor)\n",
    "input_dataset = [tensor.float() for tensor in input_dataset] \n",
    "\n",
    "stacked_tensor = torch.stack(input_dataset)\n",
    "input_dataset = stacked_tensor.cpu().numpy()      \n",
    "input_dataset = [torch.tensor(data).to(device).float() for data in input_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0c8e270-3b73-4589-a930-4ef3ec10a2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of the matrixG: 524\n",
      "g pirme\n",
      "Rank of the matrixG': 109\n",
      "(524, 524)\n",
      "(524,)\n",
      "(524, 524)\n",
      "Number of eigenvalues greater than 0: 109\n",
      "\n",
      "Embedding of image 26 for Pencorr (A'A): [-2.78185906e-01 -1.06362016e-01 -5.33075421e-01  8.07953055e-02\n",
      "  9.40345277e-02  1.40365128e-01  3.91192057e-01  1.08280290e-01\n",
      " -1.64074012e-01 -2.56507483e-01 -1.25167470e-02 -2.42354675e-01\n",
      " -9.96265764e-02  3.46622220e-02 -1.16245588e-01 -1.71865951e-02\n",
      " -2.23562205e-02 -6.73680041e-02 -1.05502716e-01  4.33577809e-03\n",
      " -2.01690409e-01  2.82761475e-02 -6.85372606e-02 -3.25264456e-02\n",
      "  7.69627828e-02 -3.02809748e-02  2.13031812e-02  1.53799084e-01\n",
      "  2.41908145e-02 -1.11759033e-01 -4.12684400e-02 -4.82998647e-02\n",
      " -9.80980837e-02  1.26195227e-01  2.59539252e-02  6.56797623e-02\n",
      " -5.64430410e-02  4.56421766e-02  4.86160220e-02  3.17059862e-02\n",
      "  9.61130347e-03  8.81387713e-02  9.43861637e-02  5.95682610e-02\n",
      " -4.38311294e-02  5.21337612e-02  6.79434336e-02  1.56524616e-03\n",
      "  2.67777740e-02  8.91514756e-03 -4.04925729e-02  1.38406157e-02\n",
      " -8.47800905e-03  1.63823069e-03  1.11973712e-01 -2.99256083e-02\n",
      " -5.54656905e-03  1.31436051e-02  5.67952643e-03 -2.63638005e-02\n",
      " -1.41772952e-03 -1.19173198e-01  1.89767493e-02  2.77671206e-02\n",
      " -8.56159276e-02  1.00580633e-02  7.69885370e-02  3.57493587e-02\n",
      "  1.90750869e-02  5.61416850e-02  2.61658424e-02 -5.66105867e-02\n",
      "  8.26655744e-03 -4.30517422e-02  7.40956948e-03  2.88969242e-02\n",
      " -3.23625076e-02 -1.14551360e-02 -4.23382007e-03  4.09452844e-02\n",
      " -3.30186083e-02  6.32203815e-03 -2.49338500e-04 -2.63213304e-02\n",
      " -5.76446982e-03 -3.79750821e-02  2.62567415e-02  1.20719017e-02\n",
      "  4.30740427e-02 -1.24525131e-02 -1.86115656e-03  1.90301396e-02\n",
      "  9.66938048e-03 -1.10176514e-02  1.92626022e-02 -8.74696303e-03\n",
      " -2.78069776e-02 -2.82237772e-02 -1.81112954e-02  9.00457002e-03\n",
      " -1.44809205e-02 -1.35493074e-02  5.37487216e-03 -2.41490050e-02\n",
      "  3.68086436e-03  7.14097324e-03 -1.11730439e-02 -7.20966157e-03\n",
      " -8.02399372e-04  1.71372784e-09  2.90912700e-09 -1.32761589e-09\n",
      " -1.15328913e-09  1.74665699e-09  2.49482177e-09  2.47819474e-09\n",
      "  3.01366994e-09  1.26414716e-09  3.85223069e-10  9.98646233e-10\n",
      " -2.09322816e-09 -4.19162983e-09 -2.67065552e-09  4.95194470e-09\n",
      " -1.97259452e-09  1.58811568e-09  6.75559044e-10  8.03413186e-09\n",
      " -5.89554622e-09 -2.57339013e-10  3.91847128e-09 -5.43744476e-09\n",
      " -7.27662203e-10  6.19698696e-10 -1.33849208e-09 -5.15732998e-11\n",
      "  2.36153219e-09  3.15989156e-09 -1.61507073e-09 -2.28359852e-09\n",
      " -1.25185347e-09  1.26156687e-09 -2.66091453e-09 -8.70003735e-10\n",
      "  2.37848587e-09 -5.84790111e-09  2.41278916e-10 -2.10197289e-10\n",
      " -1.47948661e-09  3.08353404e-09  9.91327945e-10  6.71434787e-10\n",
      " -1.00689306e-09  1.35596980e-09 -2.52621028e-09 -5.26245210e-10\n",
      " -1.25534216e-10 -1.11258002e-09 -3.91960556e-09 -1.02868126e-09\n",
      "  3.07792846e-09  4.98696139e-10 -1.27166479e-09 -2.09131152e-10\n",
      "  3.10901922e-10 -5.32866065e-10 -1.33014426e-09  1.25536871e-09\n",
      "  1.23058047e-09 -2.41758985e-09  6.12911663e-10 -9.97949091e-10\n",
      " -1.85753376e-09 -4.27302884e-09  3.36871494e-09 -1.11317265e-09\n",
      "  2.91685753e-09  2.11791538e-09 -9.10177072e-10  1.06097758e-09\n",
      "  2.26167198e-09 -3.75763143e-09  2.62257008e-09 -7.64010023e-10\n",
      "  2.63914037e-09  3.03057918e-10  1.41685902e-10 -1.58040542e-09\n",
      "  2.11952718e-09  3.30743263e-09  8.15813026e-10  1.20481881e-09\n",
      "  6.28846417e-10  8.29230020e-10  1.97763434e-09  1.02362606e-09\n",
      " -1.54497084e-09 -3.59238764e-10 -1.72621563e-09  2.97311802e-09\n",
      "  1.90267869e-09  6.64175563e-11  1.45578028e-09  2.08734037e-09\n",
      "  2.57945194e-09  1.28066635e-10  2.50321699e-09  1.87557380e-09\n",
      "  1.98560860e-09  3.14399721e-09 -3.80540688e-09  7.23775972e-10\n",
      " -1.19595705e-09  1.25837480e-09  4.35154284e-10  2.42345298e-09\n",
      "  2.87069955e-09  3.08395038e-09  3.08330823e-09  7.10244287e-10\n",
      " -1.91874354e-09  1.54609799e-09 -1.66777082e-09  9.53834828e-11\n",
      " -8.82649258e-10  2.69159943e-09 -2.17680143e-09 -6.99128292e-11\n",
      "  1.25410367e-10  6.10062889e-10  1.93167069e-09 -9.01617559e-10\n",
      " -2.62678381e-09 -1.36329588e-09  5.83143372e-10 -8.34966777e-10\n",
      "  1.65083950e-10 -1.91228810e-10 -2.33808279e-10  1.90759334e-09\n",
      "  1.25275407e-09  3.03123371e-10  1.31441198e-09  8.73587052e-10\n",
      " -1.20852942e-09  2.28752270e-09  2.02947243e-09  6.27317944e-10\n",
      "  4.97224113e-10  6.06365763e-10  1.14532426e-10  4.35674090e-10\n",
      "  1.27139288e-10 -1.24013985e-09  5.53133596e-12 -2.05823226e-10\n",
      "  4.79927968e-10 -6.56446154e-10 -5.88754611e-10  1.88653485e-09\n",
      " -3.55007745e-11 -9.18416625e-10  7.64759298e-10  8.62058636e-10\n",
      " -5.08370775e-10 -4.90484682e-11  9.08443990e-10 -9.65370525e-10\n",
      " -2.50210914e-09 -4.09620627e-10 -1.55467809e-09 -1.01390804e-09\n",
      "  2.20989415e-10  9.32026641e-10 -1.42330189e-10  1.30262363e-09\n",
      " -1.72435522e-09 -3.38239908e-10 -5.92401465e-10  2.73674194e-10\n",
      "  2.09381368e-09  9.75145255e-10 -3.78034154e-10  1.69794142e-10\n",
      "  9.20883965e-10 -8.99054175e-10  7.20608830e-10 -1.26075150e-09\n",
      "  1.18404273e-10 -9.40791079e-11 -4.40971708e-10 -1.26603032e-10\n",
      "  8.34698375e-10 -3.63051934e-10 -1.84395760e-10  5.55442998e-10\n",
      "  3.67938331e-10  6.26811599e-11 -4.37841134e-10  3.53130458e-11\n",
      " -1.14113554e-11  2.56704692e-10  9.18099493e-11  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00] (512, 524) 512\n",
      "Number of elements not close to tolerance 1e-5: 109\n",
      "Number of elements not close to 0: 303\n",
      "g\n",
      "(524, 524)\n",
      "(524,)\n",
      "(524, 524)\n",
      "Number of eigenvalues greater than tolerance: 274\n"
     ]
    }
   ],
   "source": [
    "# -------------- mega insane debug -----------------\n",
    "tolerance = 1e-6\n",
    "matrixG = imgcalc.get_matrixG(testSample, imageProductType)\n",
    "\n",
    "rank = np.linalg.matrix_rank(matrixG)\n",
    "print(\"Rank of the matrixG:\", rank)\n",
    "\n",
    "nDim = 128\n",
    "# original image product matrix not PSD, after transformation,\n",
    "matrixGprime = embedfunc.pencorr(matrixG, nDim) #reduce matrixG rank from image set size to nDim\n",
    "\n",
    "print(\"g pirme\")\n",
    "rank = np.linalg.matrix_rank(matrixGprime) \n",
    "''' \n",
    "given 753 unique training samples, rank of matrixG is by right 753 \n",
    "ndim 512: rank of g' = 120, 120 positive eigenvalues for g', 380 positive eigenvalues for g\n",
    "ndim 256: rank of g' = 120, 120 positive eigenvalues for g', 380 positive eigenvalues for g\n",
    "ndim 64: rank of g' = 64, 64 positive eigenvalues for g', 380 positive eigenvalues for g\n",
    "\n",
    "somewhere in the algorithm, it is coded such that pencorr striaghtaway finds the optimum rank of a matrix and minimises it\n",
    "once rank is minimised to its optimum, the number of positive eigenvalues is only that number.\n",
    "unless we set nDim < rank, we cannot change the number of positive eigenvalues.\n",
    "this overall limits the number of dimensions we can test. \n",
    "\n",
    "essentially, since rank of g' determines the vector space formed by the rows and columns (linearly independent rows or columns in matrix),\n",
    "the rank of a matrix is the number of non-zero eigenvalues of a matrix, which is why limiting the rank of the matrix to 120 only give\n",
    "120 non-zero elements in our embedding dimension. \n",
    "'''\n",
    "print(\"Rank of the matrixG':\", rank)\n",
    "eigenvalues, eigenvectors = np.linalg.eig(matrixGprime)\n",
    "print(matrixGprime.shape) #753x753\n",
    "print(eigenvalues.shape) #753\n",
    "print(eigenvectors.shape) #753x753\n",
    "num_positive_eigenvalues = np.sum(eigenvalues > tolerance) \n",
    "print(\"Number of eigenvalues greater than 0:\", num_positive_eigenvalues)\n",
    "\n",
    "matrixA = imgcalc.get_matrixA(matrixG, embeddingType, weight)\n",
    "print(f\"\\nEmbedding of image {index1} for Pencorr (A'A): {matrixA[:,index1]} {matrixA.shape} {matrixA[:,index1].size}\")\n",
    "count_not_close_to_zero = np.sum(np.abs(matrixA[:,index1]) > tolerance)\n",
    "print(\"Number of elements not close to tolerance 1e-5:\", count_not_close_to_zero)\n",
    "\n",
    "count_to_zero = np.sum(np.abs(matrixA[:,index1]) > 0)\n",
    "print(\"Number of elements not close to 0:\", count_to_zero)\n",
    "\n",
    "print(\"g\")\n",
    "eigenvalues, eigenvectors = np.linalg.eig(matrixG)\n",
    "print(matrixG.shape) #753x753\n",
    "print(eigenvalues.shape) #753\n",
    "print(eigenvectors.shape)\n",
    "num_positive_eigenvalues = np.sum(eigenvalues > tolerance) #380 ????????\n",
    "print(\"Number of eigenvalues greater than tolerance:\", num_positive_eigenvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949bbea2-4435-4371-bb15-b985189bc6a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8908b83c-558c-42fd-bd3c-e820501de7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (test)",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
