{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec884e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Uni\\DSOInternship\\VecRepV3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "path = os.path.abspath(\"../\")\n",
    "sys.path.append(path)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6552a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, TensorDataset, Sampler, random_split, Dataset, Subset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from line_profiler import profile\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "\n",
    "\n",
    "import src.helpers.MetricUtilities as metrics\n",
    "from functools import partial\n",
    "\n",
    "from mtree.mtree import MTree\n",
    "import mtree.mtree as mtree\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "%reload_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f094dfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "path = os.path.abspath(\"../\")\n",
    "sys.path.append(path)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, TensorDataset, Sampler, random_split, Dataset, Subset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from line_profiler import profile\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "\n",
    "import src.helpers.MetricUtilities as metrics\n",
    "\n",
    "\n",
    "from mtree.mtree import MTree\n",
    "import mtree.mtree as mtree\n",
    "\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# TODO: Put these in a separate file for MTreeUtils...\n",
    "def getKNearestNeighbours(tree, point, k):\n",
    "    l = tree.search(point, k)\n",
    "    imgs = list(l)\n",
    "    return imgs\n",
    "\n",
    "def getMTree(data, k):\n",
    "    # k: desired number of nearest neighbours\n",
    "    tree = MTree(metrics.distance, max_node_size=k)\n",
    "    tree.add_all(data)\n",
    "    return tree\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "\n",
    "        self.imgs_path = \"../data/imdb_wiki/\"\n",
    "        file_list = glob.glob(self.imgs_path + \"*\")\n",
    "        self.images = []\n",
    "        for class_path in file_list:\n",
    "            for dir_path in glob.glob(class_path + \"/*\"):\n",
    "                for img_path in glob.glob(dir_path + \"/*.jpg\"):\n",
    "                    self.images.append(img_path)\n",
    "\n",
    "    # Defining the length of the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    # Defining the method to get an item from the dataset\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.images[index]\n",
    "        image = Image.open(image_path)\n",
    "        image = transforms.functional.to_grayscale(image)\n",
    "\n",
    "        # Applying the transform\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image.squeeze().to('cpu').numpy()\n",
    "\n",
    "class CustomDatasetMStar(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "\n",
    "        self.imgs_path = \"../data/mstar/Padded_imgs/\"\n",
    "        file_list = glob.glob(self.imgs_path + \"*\")\n",
    "        self.data = []\n",
    "        for class_path in file_list:\n",
    "            class_name = class_path.split(\"/\")[-1]\n",
    "            for img_path in glob.glob(class_path + \"/*.JPG\"):\n",
    "                self.data.append([img_path, class_name])\n",
    "        #print(self.data)\n",
    "        self.class_map = {\"2S1\" : 0, \"BRDM_2\": 1, \"BTR_60\": 2, \"D7\": 3, \"SLICY\": 4, \"T62\": 5, \"ZIL131\": 6, \"ZSU_23_4\": 7}\n",
    "\n",
    "    # Defining the length of the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    # Defining the method to get an item from the dataset\n",
    "    def __getitem__(self, index):\n",
    "        data_path = self.data[index]\n",
    "        image = Image.open(data_path[0])\n",
    "        image = transforms.functional.to_grayscale(image)\n",
    "        class_id = self.class_map[data_path[1]]\n",
    "        # Applying the transform\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image.squeeze().to('cpu').numpy(), class_id\n",
    "\n",
    "def get_data(size):\n",
    "    transform = transforms.Compose([\n",
    "    transforms.Resize((size, size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    return CustomDataset(transform)\n",
    "\n",
    "def get_data_MStar(size):\n",
    "    transform = transforms.Compose([\n",
    "    transforms.Resize((size, size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    return CustomDatasetMStar(transform)\n",
    "\n",
    "def mtree_ncc_query_sample_size(max_node_size=12, image_size=32, k=7, runs=2, sample_sizes=[1]):\n",
    "    total_time_ncc = 0\n",
    "    total_time_mtree = 0\n",
    "    avg_times_ncc = []\n",
    "    avg_times_mtree = []\n",
    "\n",
    "    data = get_data_MStar(image_size)\n",
    "\n",
    "    print(f\"Average runtime of querying mtree and ncc for {k} NN over {runs} runs with image size {image_size} and max node size {max_node_size} and variable sample size\")\n",
    "    for i in range(len(sample_sizes)):\n",
    "        print(f\"NOW TRYING sample size: {sample_sizes[i]}\")\n",
    "        total_time_ncc = 0\n",
    "        total_time_mtree = 0\n",
    "\n",
    "        sample_indices = random.sample(range(len(data)), sample_sizes[i])\n",
    "        sampled_test_data = Subset(data, sample_indices)\n",
    "\n",
    "        testSample = [item[0] for item in sampled_test_data]\n",
    "        \n",
    "\n",
    "        tree = getMTree(testSample, max_node_size)\n",
    "\n",
    "        # trans = transforms.Compose([transforms.Resize(img_sizes[i])])\n",
    "        # t_MNIST_data = trans(MNIST_data)\n",
    "\n",
    "        # for img in MNIST_data:\n",
    "        #     img = trans(img)\n",
    "\n",
    "        for _ in range(runs):\n",
    "            index1 = np.random.randint(len(data))\n",
    "            #input1=input_dataset[index1][0].squeeze().to('cpu')\n",
    "            unseen_image = data[index1][0]\n",
    "\n",
    "            start_time = time.time()\n",
    "            arr = []\n",
    "            for j in range(len(testSample)):\n",
    "                result = ImageProducts.ncc_scaled(testSample[j], unseen_image)\n",
    "                arr.append(result)\n",
    "            \n",
    "            unseen_img_arr = np.array(arr)\n",
    "            #print(unseen_img_arr)\n",
    "            imgProd_max_index = np.argpartition(unseen_img_arr, -(k+1))[-(k+1):]\n",
    "            end_time = time.time()\n",
    "\n",
    "            total_time_ncc += end_time - start_time\n",
    "\n",
    "            start_time = time.time()\n",
    "            imgs = getKNearestNeighbours(tree, unseen_image, k+1)\n",
    "            end_time = time.time()\n",
    "            total_time_mtree += end_time - start_time\n",
    "\n",
    "        avg_ncc = total_time_ncc / runs\n",
    "        avg_mtree = total_time_mtree / runs\n",
    "        avg_times_ncc.append(avg_ncc)\n",
    "        avg_times_mtree.append(avg_mtree)\n",
    "\n",
    "        # with open(\"test_mtree_query_sample_sizes_avg_times_ncc_.txt\", \"w\") as file:\n",
    "        #     file.write(f\"avg times: {str(avg_times_ncc)}\")\n",
    "        \n",
    "        # with open(\"test_mtree_query_sample_sizes_avg_times_mtree_.txt\", \"w\") as file:\n",
    "        #     file.write(f\"avg times: {str(avg_times_mtree)}\")\n",
    "\n",
    "        print(f\"Average runtime of ncc search: {avg_ncc:.6f} seconds\")\n",
    "        print(f\"Average runtime of mtree search: {avg_mtree:.6f} seconds\")\n",
    "    # plot_data_mtree_ncc(x_axis=\"Sample size\", title=f\"Average runtime of finding {k} neighbours with image size {image_size} against sample sizes\", filename=\"test_mtree_query_sample_sizes.png\", \n",
    "    #                     varied_arr=sample_sizes, data1=avg_times_ncc, data2=avg_times_mtree, max_node_size=max_node_size)\n",
    "\n",
    "\n",
    "def mtree_init_sample_size(max_node_size=12, image_size=32, k=7, runs=2, sample_sizes=[1]):\n",
    "    total_time_mtree_init = 0\n",
    "    avg_times_mtree_init = []\n",
    "\n",
    "    data = get_data_MStar(image_size)\n",
    "\n",
    "    print(f\"Average runtime of initialising mtree over {runs} runs with max node size {max_node_size} and image size {image_size} and variable sample sizes\")\n",
    "\n",
    "    for i in range(len(sample_sizes)):\n",
    "        print(f\"NOW TRYING sample size: {sample_sizes[i]}\")\n",
    "        total_time_mtree_init = 0\n",
    "\n",
    "        sample_indices = random.sample(range(len(data)), sample_sizes[i])\n",
    "        sampled_test_data = Subset(data, sample_indices)\n",
    "\n",
    "        testSample = [item[0] for item in sampled_test_data]\n",
    "        #sampled_test_data[:,0]\n",
    "\n",
    "        for _ in range(runs):\n",
    "            start_time = time.time()\n",
    "            tree = getMTree(testSample, max_node_size)\n",
    "            end_time = time.time()\n",
    "            total_time_mtree_init += end_time - start_time\n",
    "            print(f\"Finished one run of mtree init...\")\n",
    "\n",
    "        \n",
    "        avg_mtree_init = total_time_mtree_init / runs\n",
    "        avg_times_mtree_init.append(avg_mtree_init)\n",
    "\n",
    "        \n",
    "        # with open(\"test_mtree_init_sample_sizes_avg_times_mtree_init.txt\", \"w\") as file:\n",
    "        #     file.write(f\"avg times: {str(avg_times_mtree_init)}\")\n",
    "\n",
    "        print(f\"Average runtime of mtree init: {avg_mtree_init:.6f} seconds\")\n",
    "    \n",
    "    # plot_data_mtree_init(x_axis=\"Sample size\", title=f\"Average runtime of initialising mtree with image size {image_size}, max node size {max_node_size} against sample sizes\", filename=\"test_mtree_init_sample_sizes.png\", \n",
    "    #                     varied_arr=sample_sizes, data=avg_times_mtree_init, max_node_size=max_node_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5946879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average runtime of querying mtree and ncc for 7 NN over 10 runs with image size 368 and max node size 15 and variable sample size\n",
      "NOW TRYING sample size: 10\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Padded_imgs\\\\ZSU_23_4'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 9466 samples\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# note MStar is 368 by 368...\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmtree_ncc_query_sample_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_node_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m368\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 141\u001b[0m, in \u001b[0;36mmtree_ncc_query_sample_size\u001b[1;34m(max_node_size, image_size, k, runs, sample_sizes)\u001b[0m\n\u001b[0;32m    138\u001b[0m sample_indices \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data)), sample_sizes[i])\n\u001b[0;32m    139\u001b[0m sampled_test_data \u001b[38;5;241m=\u001b[39m Subset(data, sample_indices)\n\u001b[1;32m--> 141\u001b[0m testSample \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msampled_test_data\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    144\u001b[0m tree \u001b[38;5;241m=\u001b[39m getMTree(testSample, max_node_size)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# trans = transforms.Compose([transforms.Resize(img_sizes[i])])\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# t_MNIST_data = trans(MNIST_data)\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# for img in MNIST_data:\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m#     img = trans(img)\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda_envs\\testing-env\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:412\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[1;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 101\u001b[0m, in \u001b[0;36mCustomDatasetMStar.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     99\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(data_path[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    100\u001b[0m image \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mto_grayscale(image)\n\u001b[1;32m--> 101\u001b[0m class_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Applying the transform\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Padded_imgs\\\\ZSU_23_4'"
     ]
    }
   ],
   "source": [
    "# 9466 samples\n",
    "# note MStar is 368 by 368...\n",
    "\n",
    "mtree_ncc_query_sample_size(max_node_size=15, image_size=368, k=7, runs=10, sample_sizes=[10, 100, 1000, 2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d96f5a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9466\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Padded_imgs\\\\SLICY'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m sample_indices \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data)), \u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m      5\u001b[0m sampled_test_data \u001b[38;5;241m=\u001b[39m Subset(data, sample_indices)\n\u001b[1;32m----> 7\u001b[0m testSample \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msampled_test_data\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      8\u001b[0m classes \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m sampled_test_data]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# class_map = {\"2S1\" : 0, \"BRDM_2\": 1, \"BTR_60\": 2, \"D7\": 3, \"SLICY\": 4, \"T62\": 5, \"ZIL131\": 6, \"ZSU_23_4\": 7}\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda_envs\\testing-env\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:412\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[1;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 101\u001b[0m, in \u001b[0;36mCustomDatasetMStar.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     99\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(data_path[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    100\u001b[0m image \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mto_grayscale(image)\n\u001b[1;32m--> 101\u001b[0m class_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Applying the transform\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Padded_imgs\\\\SLICY'"
     ]
    }
   ],
   "source": [
    "\n",
    "k=7\n",
    "data = get_data_MStar(368)\n",
    "print(len(data))\n",
    "sample_indices = random.sample(range(len(data)), 100)\n",
    "sampled_test_data = Subset(data, sample_indices)\n",
    "\n",
    "testSample = [item[0] for item in sampled_test_data]\n",
    "classes = [item[1] for item in sampled_test_data]\n",
    "\n",
    "# class_map = {\"2S1\" : 0, \"BRDM_2\": 1, \"BTR_60\": 2, \"D7\": 3, \"SLICY\": 4, \"T62\": 5, \"ZIL131\": 6, \"ZSU_23_4\": 7}\n",
    "\n",
    "tree = getMTree(testSample, 12)\n",
    "\n",
    "index1 = random.choice(sample_indices)\n",
    "#input1=input_dataset[index1][0].squeeze().to('cpu')\n",
    "unseen_image = data[index1][0]\n",
    "unseen_image_class = data[index1][1]\n",
    "\n",
    "arr = []\n",
    "for j in range(len(testSample)):\n",
    "    result = ImageProducts.ncc_scaled(testSample[j], unseen_image)\n",
    "    arr.append(result)\n",
    "\n",
    "unseen_img_arr = np.array(arr)\n",
    "#print(unseen_img_arr)\n",
    "imgProd_max_index = np.argpartition(unseen_img_arr, -(k+1))[-(k+1):]\n",
    "\n",
    "num_same_class = 0\n",
    "\n",
    "print(f\"Unseen img class: {unseen_image_class}\")\n",
    "for i in imgProd_max_index:\n",
    "    img_class = classes[i]\n",
    "    print(f\"Index {i}, Class {img_class}\")\n",
    "    if (img_class == unseen_image_class):\n",
    "        num_same_class += 1\n",
    "\n",
    "print(num_same_class)\n",
    "\n",
    "\n",
    "imgs = getKNearestNeighbours(tree, unseen_image, k+1)\n",
    "\n",
    "\n",
    "def imgs_to_indices(img_arr, testSample):\n",
    "    ind_arr = []\n",
    "    for img in img_arr:\n",
    "        for i in range(len(testSample)):\n",
    "            if (metrics.distance(img, testSample[i]) < 0.00001):\n",
    "                ind_arr.append(i)\n",
    "                break\n",
    "    \n",
    "    return ind_arr\n",
    "\n",
    "ind_arr = imgs_to_indices(imgs, testSample)\n",
    "print(ind_arr)\n",
    "print(imgProd_max_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0024020e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9466\n",
      "Unseen img class: 3\n",
      "Index 9, Class 6\n",
      "Index 8, Class 2\n",
      "Index 4, Class 3\n",
      "Index 7, Class 1\n",
      "Index 6, Class 6\n",
      "Index 3, Class 5\n",
      "Index 1, Class 4\n",
      "Index 2, Class 3\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 121\u001b[39m\n\u001b[32m    117\u001b[39m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ind_arr\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m ind_arr = imgs_to_indices(imgs, testSample)\n\u001b[32m    122\u001b[39m \u001b[38;5;28mprint\u001b[39m(ind_arr)\n\u001b[32m    123\u001b[39m \u001b[38;5;28mprint\u001b[39m(imgProd_max_index)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 115\u001b[39m, in \u001b[36mimgs_to_indices\u001b[39m\u001b[34m(img_arr, testSample)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m img_arr:\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(testSample)):\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m (metrics.distance(img, testSample[i]) < \u001b[32m0.00001\u001b[39m):\n\u001b[32m    116\u001b[39m             ind_arr.append(i)\n\u001b[32m    117\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Uni\\DSOInternship\\VecRepV3\\src\\helpers\\MetricUtilities.py:15\u001b[39m, in \u001b[36mdistance\u001b[39m\u001b[34m(image1, image2)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdistance\u001b[39m(image1, image2):\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m#print(image1)\u001b[39;00m\n\u001b[32m     13\u001b[39m     \u001b[38;5;66;03m#print(image2)\u001b[39;00m\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m#print(min(ImageProducts.ncc(image1, image2), 1))\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     ncc = \u001b[38;5;28mmin\u001b[39m(ImageProducts.ncc(image1, image2), \u001b[32m1\u001b[39m)\n\u001b[32m     16\u001b[39m     ncc = \u001b[38;5;28mmax\u001b[39m(ncc, \u001b[32m0\u001b[39m)\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m#print(math.acos(ImageProducts.ncc(image1, image2)))\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Uni\\DSOInternship\\VecRepV3\\src\\data_processing\\ImageProducts.py:160\u001b[39m, in \u001b[36mncc\u001b[39m\u001b[34m(mainImg, tempImg)\u001b[39m\n\u001b[32m    157\u001b[39m mainImg = np.asarray(mainImg, np.single)  \u001b[38;5;66;03m# Setting data types of array\u001b[39;00m\n\u001b[32m    158\u001b[39m tempImg = np.asarray(tempImg, np.single)\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m corr = cv2.matchTemplate(mainImg, tempImg, cv2.TM_CCORR_NORMED)\n\u001b[32m    162\u001b[39m min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(corr)\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m max_val\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def ncc(mainImg, tempImg) -> float:\n",
    "    \"\"\"\n",
    "    :param mainImg: Main image to be scanned\n",
    "    :param tempImg: Template image to be scanned over the main\n",
    "    :return: Max value of the ncc\n",
    "\n",
    "    Applies NCC of the template image over the main image and returns the max value obtained.\n",
    "    When the template image kernel exceeds the bounds, wraps to the other side of the main image\n",
    "    \"\"\"\n",
    "    if np.count_nonzero(mainImg) == 0:\n",
    "        if np.count_nonzero(tempImg) == 0:\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "    mainImg = np.pad(mainImg, max(len(mainImg), len(mainImg[0])),\n",
    "                     'wrap')  # Padding the main image with wrapped values to simulate wrapping\n",
    "\n",
    "    mainImg = np.asarray(mainImg, np.single)  # Setting data types of array\n",
    "    tempImg = np.asarray(tempImg, np.single)\n",
    "\n",
    "    corr = cv2.matchTemplate(mainImg, tempImg, cv2.TM_CCORR_NORMED)\n",
    "\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(corr)\n",
    "\n",
    "    return max_val\n",
    "\n",
    "def ncc_scaled(mainImg, tempImg) -> float:\n",
    "    \"\"\"\n",
    "    :param mainImg: Main image to be scanned\n",
    "    :param tempImg: Template image to be scanned over the main\n",
    "    :return: Max value of the ncc, with scaled bounds of [-1,1]\n",
    "    \"\"\"\n",
    "    return ncc(mainImg, tempImg) * 2 - 1\n",
    "\n",
    "\n",
    "class CustomDatasetMStar(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "\n",
    "        self.imgs_path = \"../data/mstar/Padded_imgs/\"\n",
    "        file_list = glob.glob(self.imgs_path + \"*\")\n",
    "        self.data = []\n",
    "        for class_path in file_list:\n",
    "            class_name = class_path.split(\"\\\\\")[-1]\n",
    "            for img_path in glob.glob(class_path + \"/*.JPG\"):\n",
    "                self.data.append([img_path, class_name])\n",
    "        #print(self.data)\n",
    "        self.class_map = {\"2S1\" : 0, \"BRDM_2\": 1, \"BTR_60\": 2, \"D7\": 3, \"SLICY\": 4, \"T62\": 5, \"ZIL131\": 6, \"ZSU_23_4\": 7}\n",
    "\n",
    "    # Defining the length of the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    # Defining the method to get an item from the dataset\n",
    "    def __getitem__(self, index):\n",
    "        data_path = self.data[index]\n",
    "        image = Image.open(data_path[0])\n",
    "        image = transforms.functional.to_grayscale(image)\n",
    "        class_id = self.class_map[data_path[1]]\n",
    "        # Applying the transform\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image.squeeze().to('cpu').numpy(), class_id\n",
    "\n",
    "k=7\n",
    "data = get_data_MStar(368)\n",
    "print(len(data))\n",
    "sample_indices = random.sample(range(len(data)), 10)\n",
    "sampled_test_data = Subset(data, sample_indices)\n",
    "\n",
    "testSample = [item[0] for item in sampled_test_data]\n",
    "classes = [item[1] for item in sampled_test_data]\n",
    "\n",
    "# class_map = {\"2S1\" : 0, \"BRDM_2\": 1, \"BTR_60\": 2, \"D7\": 3, \"SLICY\": 4, \"T62\": 5, \"ZIL131\": 6, \"ZSU_23_4\": 7}\n",
    "\n",
    "tree = getMTree(testSample, 12)\n",
    "\n",
    "index1 = random.choice(sample_indices)\n",
    "#input1=input_dataset[index1][0].squeeze().to('cpu')\n",
    "unseen_image = data[index1][0]\n",
    "unseen_image_class = data[index1][1]\n",
    "\n",
    "arr = []\n",
    "for j in range(len(testSample)):\n",
    "    result = ncc_scaled(testSample[j], unseen_image)\n",
    "    arr.append(result)\n",
    "\n",
    "unseen_img_arr = np.array(arr)\n",
    "#print(unseen_img_arr)\n",
    "imgProd_max_index = np.argpartition(unseen_img_arr, -(k+1))[-(k+1):]\n",
    "\n",
    "num_same_class = 0\n",
    "\n",
    "print(f\"Unseen img class: {unseen_image_class}\")\n",
    "for i in imgProd_max_index:\n",
    "    img_class = classes[i]\n",
    "    print(f\"Index {i}, Class {img_class}\")\n",
    "    if (img_class == unseen_image_class):\n",
    "        num_same_class += 1\n",
    "\n",
    "print(num_same_class)\n",
    "\n",
    "\n",
    "imgs = getKNearestNeighbours(tree, unseen_image, k+1)\n",
    "\n",
    "\n",
    "def imgs_to_indices(img_arr, testSample):\n",
    "    ind_arr = []\n",
    "    for img in img_arr:\n",
    "        for i in range(len(testSample)):\n",
    "            if (metrics.distance(img, testSample[i]) < 0.00001):\n",
    "                ind_arr.append(i)\n",
    "                break\n",
    "    \n",
    "    return ind_arr\n",
    "\n",
    "ind_arr = imgs_to_indices(imgs, testSample)\n",
    "print(ind_arr)\n",
    "print(imgProd_max_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cfdd451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9466\n",
      "0.8721287250518799\n",
      "32470.98828125\n",
      "0.8721287\n"
     ]
    }
   ],
   "source": [
    "import scipy.fft\n",
    "import math\n",
    "\n",
    "def ncc(mainImg, tempImg) -> float:\n",
    "    \"\"\"\n",
    "    :param mainImg: Main image to be scanned\n",
    "    :param tempImg: Template image to be scanned over the main\n",
    "    :return: Max value of the ncc\n",
    "\n",
    "    Applies NCC of the template image over the main image and returns the max value obtained.\n",
    "    When the template image kernel exceeds the bounds, wraps to the other side of the main image\n",
    "    \"\"\"\n",
    "    if np.count_nonzero(mainImg) == 0:\n",
    "        if np.count_nonzero(tempImg) == 0:\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "    mainImg = np.pad(mainImg, max(len(mainImg), len(mainImg[0])),\n",
    "                     'wrap')  # Padding the main image with wrapped values to simulate wrapping\n",
    "\n",
    "    mainImg = np.asarray(mainImg, np.single)  # Setting data types of array\n",
    "    tempImg = np.asarray(tempImg, np.single)\n",
    "\n",
    "    corr = cv2.matchTemplate(mainImg, tempImg, cv2.TM_CCORR_NORMED)\n",
    "\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(corr)\n",
    "\n",
    "    return max_val\n",
    "\n",
    "def ncc_unnormed(mainImg, tempImg) -> float:\n",
    "    \"\"\"\n",
    "    :param mainImg: Main image to be scanned\n",
    "    :param tempImg: Template image to be scanned over the main\n",
    "    :return: Max value of the ncc\n",
    "\n",
    "    Applies NCC of the template image over the main image and returns the max value obtained.\n",
    "    When the template image kernel exceeds the bounds, wraps to the other side of the main image\n",
    "    \"\"\"\n",
    "    if np.count_nonzero(mainImg) == 0:\n",
    "        if np.count_nonzero(tempImg) == 0:\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "    mainImg = np.pad(mainImg, max(len(mainImg), len(mainImg[0])),\n",
    "                     'wrap')  # Padding the main image with wrapped values to simulate wrapping\n",
    "\n",
    "    mainImg = np.asarray(mainImg, np.single)  # Setting data types of array\n",
    "    tempImg = np.asarray(tempImg, np.single)\n",
    "\n",
    "    corr = cv2.matchTemplate(mainImg, tempImg, cv2.TM_CCORR)\n",
    "\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(corr)\n",
    "\n",
    "    return max_val\n",
    "\n",
    "dataset = get_data_MStar(300)\n",
    "\n",
    "\n",
    "print(len(dataset))\n",
    "test_img, test_class = dataset[10]\n",
    "test_img2, test_class2 = dataset[20]\n",
    "m = test_img.shape[0]\n",
    "\n",
    "ncc_score_un = ncc_unnormed(test_img, test_img2)\n",
    "ncc_score = ncc(test_img, test_img2)\n",
    "print(ncc_score)\n",
    "print(ncc_score_un)\n",
    "\n",
    "\n",
    "def ncc_fft(mainImg, tempImg):\n",
    "    A = scipy.fft.fft2(test_img)\n",
    "    B = scipy.fft.fft2(test_img2)\n",
    "\n",
    "    Z = scipy.fft.ifft2(np.conj(A) * B).real\n",
    "\n",
    "    auto_A = scipy.fft.ifft2(np.conj(A) * A).real\n",
    "    auto_B = scipy.fft.ifft2(np.conj(B) * B).real\n",
    "    auto_A_sqrt = np.sqrt(auto_A)\n",
    "    auto_B_sqrt = np.sqrt(auto_B)\n",
    "    denom = np.multiply(auto_A_sqrt, auto_B_sqrt).max() # (THIS WORKS.) (Basically uhm so the normalization amt should be the same throughout? I'm not v sure why this works...)\n",
    "\n",
    "    return np.divide(Z, denom).max()\n",
    "\n",
    "print(ncc_fft(test_img, test_img2))\n",
    "\n",
    "def ncc_naive(mainImg, tempImg):\n",
    "    if np.count_nonzero(mainImg) == 0:\n",
    "        if np.count_nonzero(tempImg) == 0:\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "    mainImg = np.pad(mainImg, max(len(mainImg), len(mainImg[0])),\n",
    "                     'wrap')  # Padding the main image with wrapped values to simulate wrapping\n",
    "\n",
    "    mainImg = np.asarray(mainImg, np.single)  # Setting data types of array\n",
    "    tempImg = np.asarray(tempImg, np.single)\n",
    "    m = tempImg.shape[0]\n",
    "    ncc_arr = np.ones((2*m, 2*m))\n",
    "    for i in range(2 * m):\n",
    "        for j in range(2 * m):\n",
    "            sum = 0\n",
    "            sum_norm_main = 0\n",
    "            sum_norm_temp = 0\n",
    "            for x in range(m):\n",
    "                for y in range(m):\n",
    "                    sum += mainImg[x + i][y + j] * tempImg[x][y]\n",
    "                    sum_norm_main += (mainImg[x+i][y+j])**2\n",
    "                    sum_norm_temp += (tempImg[x][y])**2\n",
    "            \n",
    "            ncc_arr[i][j] = (sum) / (math.sqrt(sum_norm_main * sum_norm_temp))\n",
    "    \n",
    "    return ncc_arr.max()\n",
    "\n",
    "\n",
    "# print(ncc_naive(test_img, test_img2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08d0587",
   "metadata": {},
   "source": [
    "## TEST NUMBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab39c33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba as nb\n",
    "\n",
    "@nb.njit\n",
    "def ncc_fft_numba(mainImg, tempImg):\n",
    "    A = scipy.fft.fft2(test_img)\n",
    "    B = scipy.fft.fft2(test_img2)\n",
    "\n",
    "    Z = scipy.fft.ifft2(np.conj(A) * B).real\n",
    "    # IT'S OK UP TO THIS POINT!!\n",
    "\n",
    "    auto_A = scipy.fft.ifft2(np.conj(A) * A).real\n",
    "    auto_B = scipy.fft.ifft2(np.conj(B) * B).real\n",
    "    auto_A_sqrt = np.sqrt(auto_A)\n",
    "    auto_B_sqrt = np.sqrt(auto_B)\n",
    "    denom = np.multiply(auto_A_sqrt, auto_B_sqrt).max() # (THIS WORKS.) (Basically uhm so the normalization amt should be the same throughout? I'm not v sure why this works but not the other...)\n",
    "\n",
    "    return np.divide(Z, denom).max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd353a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising\n",
    "\n",
    "ncc_score = ncc_fft_numba(test_img, test_img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c9dea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocket-fft ncc fft runtime: 0.03053863300019293\n",
      "ncc fft runtime: 0.04279141920001712\n",
      "cv2 ncc runtime: 0.09055825790012023\n"
     ]
    }
   ],
   "source": [
    "# Rocket-fft consistently faster! Yippee.\n",
    "import time\n",
    "\n",
    "runs = 1000\n",
    "ttime = 0\n",
    "\n",
    "for i in range(runs):\n",
    "    start_time = time.perf_counter()\n",
    "    ncc_score = ncc_fft_numba(test_img, test_img2)\n",
    "    end_time = time.perf_counter()\n",
    "    ttime += end_time - start_time\n",
    "\n",
    "print(f\"rocket-fft ncc fft runtime: {ttime / runs}\")\n",
    "\n",
    "for i in range(runs):\n",
    "    start_time = time.perf_counter()\n",
    "    ncc_score = ncc_fft(test_img, test_img2)\n",
    "    end_time = time.perf_counter()\n",
    "    ttime += end_time - start_time\n",
    "\n",
    "print(f\"ncc fft runtime: {ttime / runs}\")\n",
    "\n",
    "for i in range(runs):\n",
    "    start_time = time.perf_counter()\n",
    "    ncc_score = ncc(test_img, test_img2)\n",
    "    end_time = time.perf_counter()\n",
    "    ttime += end_time - start_time\n",
    "\n",
    "print(f\"cv2 ncc runtime: {ttime / runs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3ca163",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rocket-fft-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
