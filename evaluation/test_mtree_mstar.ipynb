{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec884e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "path = os.path.abspath(\"../\")\n",
    "sys.path.append(path)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6552a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, TensorDataset, Sampler, random_split, Dataset, Subset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from line_profiler import profile\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "\n",
    "import src.data_processing.ImageCalculations as imgcalc\n",
    "import src.visualization.ImagePlots as imgplt\n",
    "import src.helpers.ModelUtilities as models\n",
    "import src.helpers.TCNNModelUtilities as tcnnmodels\n",
    "import src.data_processing.Utilities as utils\n",
    "import src.helpers.FilepathUtils as Futils\n",
    "import src.data_processing.EmbeddingFunctions as embedfunc\n",
    "import src.data_processing.ImageProducts as ImageProducts\n",
    "import src.helpers.MetricUtilities as metrics\n",
    "\n",
    "from src.visualization import BFmethod\n",
    "from functools import partial\n",
    "from learnable_polyphase_sampling.learn_poly_sampling.layers import get_logits_model, PolyphaseInvariantDown2D, LPS\n",
    "from learnable_polyphase_sampling.learn_poly_sampling.layers.polydown import set_pool\n",
    "\n",
    "from mtree.mtree import MTree\n",
    "import mtree.mtree as mtree\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "%reload_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f094dfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "path = os.path.abspath(\"../\")\n",
    "sys.path.append(path)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, TensorDataset, Sampler, random_split, Dataset, Subset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from line_profiler import profile\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "\n",
    "import src.data_processing.ImageCalculations as imgcalc\n",
    "import src.visualization.ImagePlots as imgplt\n",
    "import src.helpers.ModelUtilities as models\n",
    "import src.helpers.TCNNModelUtilities as tcnnmodels\n",
    "import src.data_processing.Utilities as utils\n",
    "import src.helpers.FilepathUtils as Futils\n",
    "import src.data_processing.EmbeddingFunctions as embedfunc\n",
    "import src.data_processing.ImageProducts as ImageProducts\n",
    "import src.helpers.MetricUtilities as metrics\n",
    "\n",
    "from src.visualization import BFmethod\n",
    "from functools import partial\n",
    "from learnable_polyphase_sampling.learn_poly_sampling.layers import get_logits_model, PolyphaseInvariantDown2D, LPS\n",
    "from learnable_polyphase_sampling.learn_poly_sampling.layers.polydown import set_pool\n",
    "\n",
    "from mtree.mtree import MTree\n",
    "import mtree.mtree as mtree\n",
    "\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# TODO: Put these in a separate file for MTreeUtils...\n",
    "def getKNearestNeighbours(tree, point, k):\n",
    "    l = tree.search(point, k)\n",
    "    imgs = list(l)\n",
    "    return imgs\n",
    "\n",
    "def getMTree(data, k):\n",
    "    # k: desired number of nearest neighbours\n",
    "    tree = MTree(metrics.distance, max_node_size=k)\n",
    "    tree.add_all(data)\n",
    "    return tree\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "\n",
    "        self.imgs_path = \"../data/imdb_wiki/\"\n",
    "        file_list = glob.glob(self.imgs_path + \"*\")\n",
    "        self.images = []\n",
    "        for class_path in file_list:\n",
    "            for dir_path in glob.glob(class_path + \"/*\"):\n",
    "                for img_path in glob.glob(dir_path + \"/*.jpg\"):\n",
    "                    self.images.append(img_path)\n",
    "\n",
    "    # Defining the length of the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    # Defining the method to get an item from the dataset\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.images[index]\n",
    "        image = Image.open(image_path)\n",
    "        image = transforms.functional.to_grayscale(image)\n",
    "\n",
    "        # Applying the transform\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image.squeeze().to('cpu').numpy()\n",
    "\n",
    "class CustomDatasetMStar(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "\n",
    "        self.imgs_path = \"../data/mstar/Padded_imgs/\"\n",
    "        file_list = glob.glob(self.imgs_path + \"*\")\n",
    "        self.data = []\n",
    "        for class_path in file_list:\n",
    "            class_name = class_path.split(\"/\")[-1]\n",
    "            for img_path in glob.glob(class_path + \"/*.JPG\"):\n",
    "                self.data.append([img_path, class_name])\n",
    "        #print(self.data)\n",
    "        self.class_map = {\"2S1\" : 0, \"BRDM_2\": 1, \"BTR_60\": 2, \"D7\": 3, \"SLICY\": 4, \"T62\": 5, \"ZIL131\": 6, \"ZSU_23_4\": 7}\n",
    "\n",
    "    # Defining the length of the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    # Defining the method to get an item from the dataset\n",
    "    def __getitem__(self, index):\n",
    "        data_path = self.data[index]\n",
    "        image = Image.open(data_path[0])\n",
    "        image = transforms.functional.to_grayscale(image)\n",
    "        class_id = self.class_map[data_path[1]]\n",
    "        # Applying the transform\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image.squeeze().to('cpu').numpy(), class_id\n",
    "\n",
    "def get_data(size):\n",
    "    transform = transforms.Compose([\n",
    "    transforms.Resize((size, size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    return CustomDataset(transform)\n",
    "\n",
    "def get_data_MStar(size):\n",
    "    transform = transforms.Compose([\n",
    "    transforms.Resize((size, size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    return CustomDatasetMStar(transform)\n",
    "\n",
    "def mtree_ncc_query_sample_size(max_node_size=12, image_size=32, k=7, runs=2, sample_sizes=[1]):\n",
    "    total_time_ncc = 0\n",
    "    total_time_mtree = 0\n",
    "    avg_times_ncc = []\n",
    "    avg_times_mtree = []\n",
    "\n",
    "    data = get_data_MStar(image_size)\n",
    "\n",
    "    print(f\"Average runtime of querying mtree and ncc for {k} NN over {runs} runs with image size {image_size} and max node size {max_node_size} and variable sample size\")\n",
    "    for i in range(len(sample_sizes)):\n",
    "        print(f\"NOW TRYING sample size: {sample_sizes[i]}\")\n",
    "        total_time_ncc = 0\n",
    "        total_time_mtree = 0\n",
    "\n",
    "        sample_indices = random.sample(range(len(data)), sample_sizes[i])\n",
    "        sampled_test_data = Subset(data, sample_indices)\n",
    "\n",
    "        testSample = [item[0] for item in sampled_test_data]\n",
    "        \n",
    "\n",
    "        tree = getMTree(testSample, max_node_size)\n",
    "\n",
    "        # trans = transforms.Compose([transforms.Resize(img_sizes[i])])\n",
    "        # t_MNIST_data = trans(MNIST_data)\n",
    "\n",
    "        # for img in MNIST_data:\n",
    "        #     img = trans(img)\n",
    "\n",
    "        for _ in range(runs):\n",
    "            index1 = np.random.randint(len(data))\n",
    "            #input1=input_dataset[index1][0].squeeze().to('cpu')\n",
    "            unseen_image = data[index1][0]\n",
    "\n",
    "            start_time = time.time()\n",
    "            arr = []\n",
    "            for j in range(len(testSample)):\n",
    "                result = ImageProducts.ncc_scaled(testSample[j][0], unseen_image)\n",
    "                arr.append(result)\n",
    "            \n",
    "            unseen_img_arr = np.array(arr)\n",
    "            #print(unseen_img_arr)\n",
    "            imgProd_max_index = np.argpartition(unseen_img_arr, -(k+1))[-(k+1):]\n",
    "            end_time = time.time()\n",
    "\n",
    "            total_time_ncc += end_time - start_time\n",
    "\n",
    "            start_time = time.time()\n",
    "            imgs = getKNearestNeighbours(tree, unseen_image, k+1)\n",
    "            end_time = time.time()\n",
    "            total_time_mtree += end_time - start_time\n",
    "\n",
    "        avg_ncc = total_time_ncc / runs\n",
    "        avg_mtree = total_time_mtree / runs\n",
    "        avg_times_ncc.append(avg_ncc)\n",
    "        avg_times_mtree.append(avg_mtree)\n",
    "\n",
    "        # with open(\"test_mtree_query_sample_sizes_avg_times_ncc_.txt\", \"w\") as file:\n",
    "        #     file.write(f\"avg times: {str(avg_times_ncc)}\")\n",
    "        \n",
    "        # with open(\"test_mtree_query_sample_sizes_avg_times_mtree_.txt\", \"w\") as file:\n",
    "        #     file.write(f\"avg times: {str(avg_times_mtree)}\")\n",
    "\n",
    "        print(f\"Average runtime of ncc search: {avg_ncc:.6f} seconds\")\n",
    "        print(f\"Average runtime of mtree search: {avg_mtree:.6f} seconds\")\n",
    "    # plot_data_mtree_ncc(x_axis=\"Sample size\", title=f\"Average runtime of finding {k} neighbours with image size {image_size} against sample sizes\", filename=\"test_mtree_query_sample_sizes.png\", \n",
    "    #                     varied_arr=sample_sizes, data1=avg_times_ncc, data2=avg_times_mtree, max_node_size=max_node_size)\n",
    "\n",
    "\n",
    "def mtree_init_sample_size(max_node_size=12, image_size=32, k=7, runs=2, sample_sizes=[1]):\n",
    "    total_time_mtree_init = 0\n",
    "    avg_times_mtree_init = []\n",
    "\n",
    "    data = get_data_MStar(image_size)\n",
    "\n",
    "    print(f\"Average runtime of initialising mtree over {runs} runs with max node size {max_node_size} and image size {image_size} and variable sample sizes\")\n",
    "\n",
    "    for i in range(len(sample_sizes)):\n",
    "        print(f\"NOW TRYING sample size: {sample_sizes[i]}\")\n",
    "        total_time_mtree_init = 0\n",
    "\n",
    "        sample_indices = random.sample(range(len(data)), sample_sizes[i])\n",
    "        sampled_test_data = Subset(data, sample_indices)\n",
    "\n",
    "        testSample = [item[0] for item in sampled_test_data]\n",
    "        #sampled_test_data[:,0]\n",
    "\n",
    "        for _ in range(runs):\n",
    "            start_time = time.time()\n",
    "            tree = getMTree(testSample, max_node_size)\n",
    "            end_time = time.time()\n",
    "            total_time_mtree_init += end_time - start_time\n",
    "            print(f\"Finished one run of mtree init...\")\n",
    "\n",
    "        \n",
    "        avg_mtree_init = total_time_mtree_init / runs\n",
    "        avg_times_mtree_init.append(avg_mtree_init)\n",
    "\n",
    "        \n",
    "        # with open(\"test_mtree_init_sample_sizes_avg_times_mtree_init.txt\", \"w\") as file:\n",
    "        #     file.write(f\"avg times: {str(avg_times_mtree_init)}\")\n",
    "\n",
    "        print(f\"Average runtime of mtree init: {avg_mtree_init:.6f} seconds\")\n",
    "    \n",
    "    # plot_data_mtree_init(x_axis=\"Sample size\", title=f\"Average runtime of initialising mtree with image size {image_size}, max node size {max_node_size} against sample sizes\", filename=\"test_mtree_init_sample_sizes.png\", \n",
    "    #                     varied_arr=sample_sizes, data=avg_times_mtree_init, max_node_size=max_node_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5946879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average runtime of initialising mtree over 2 runs with max node size 12 and image size 128 and variable sample sizes\n",
      "NOW TRYING sample size: 100\n",
      "Finished one run of mtree init...\n",
      "Finished one run of mtree init...\n",
      "Average runtime of mtree init: 10.632416 seconds\n",
      "NOW TRYING sample size: 1000\n",
      "Finished one run of mtree init...\n",
      "Finished one run of mtree init...\n",
      "Average runtime of mtree init: 96.147403 seconds\n",
      "NOW TRYING sample size: 5000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmtree_init_sample_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_node_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruns\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 153\u001b[39m, in \u001b[36mmtree_init_sample_size\u001b[39m\u001b[34m(max_node_size, image_size, k, runs, sample_sizes)\u001b[39m\n\u001b[32m    150\u001b[39m sample_indices = random.sample(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data)), sample_sizes[i])\n\u001b[32m    151\u001b[39m sampled_test_data = Subset(data, sample_indices)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m testSample = \u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msampled_test_data\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[38;5;66;03m#sampled_test_data[:,0]\u001b[39;00m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(runs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/miniconda/envs/cupy-env/lib/python3.12/site-packages/torch/utils/data/dataset.py:412\u001b[39m, in \u001b[36mSubset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    411\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset[[\u001b[38;5;28mself\u001b[39m.indices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[32m--> \u001b[39m\u001b[32m412\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 111\u001b[39m, in \u001b[36mCustomDatasetMStar.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[32m    110\u001b[39m     data_path = \u001b[38;5;28mself\u001b[39m.data[index]\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     image = \u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m     image = transforms.functional.to_grayscale(image)\n\u001b[32m    113\u001b[39m     class_id = \u001b[38;5;28mself\u001b[39m.class_map[data_path[\u001b[32m1\u001b[39m]]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/miniconda/envs/cupy-env/lib/python3.12/site-packages/PIL/Image.py:3505\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(fp, mode, formats)\u001b[39m\n\u001b[32m   3502\u001b[39m     filename = os.fspath(fp)\n\u001b[32m   3504\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[32m-> \u001b[39m\u001b[32m3505\u001b[39m     fp = \u001b[43mbuiltins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3506\u001b[39m     exclusive_fp = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   3507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "mtree_init_sample_size(max_node_size=12, image_size=128, k=7, runs=2, sample_sizes=[100, 1000, 5000, 10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96f5a76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cupy-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
