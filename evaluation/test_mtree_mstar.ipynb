{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec884e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "path = os.path.abspath(\"../\")\n",
    "sys.path.append(path)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6552a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, TensorDataset, Sampler, random_split, Dataset, Subset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from line_profiler import profile\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "\n",
    "\n",
    "import src.helpers.MetricUtilities as metrics\n",
    "import src.data_processing.ImageProducts as ImageProducts\n",
    "from functools import partial\n",
    "\n",
    "from mtree.mtree import MTree\n",
    "import mtree.mtree as mtree\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "%reload_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f094dfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "path = os.path.abspath(\"../\")\n",
    "sys.path.append(path)\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, Subset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from line_profiler import profile\n",
    "\n",
    "import src.helpers.MetricUtilities as metrics\n",
    "\n",
    "\n",
    "from mtree.mtree import MTree\n",
    "import mtree.mtree as mtree\n",
    "\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# TODO: Put these in a separate file for MTreeUtils...\n",
    "def getKNearestNeighbours(tree, point, k):\n",
    "    l = tree.search(point, k)\n",
    "    imgs = list(l)\n",
    "    return imgs\n",
    "\n",
    "def getMTree(data, k, promote=mtree.M_LB_DIST_confirmed, partition=mtree.generalized_hyperplane, d=metrics.distance):\n",
    "    # k: desired number of nearest neighbours\n",
    "    tree = MTree(d, max_node_size=k, promote=promote, partition=partition)\n",
    "    tree.add_all(data)\n",
    "    return tree\n",
    "\n",
    "def getMTreeFFT(data, k):\n",
    "    # k: desired number of nearest neighbours\n",
    "    tree = MTree(metrics.dist_fft, max_node_size=k)\n",
    "    tree.add_all(data)\n",
    "    return tree\n",
    "\n",
    "def getMTreeFFTNumba(data, k, promote=mtree.M_LB_DIST_confirmed, partition=mtree.generalized_hyperplane):\n",
    "    # k: desired number of nearest neighbours\n",
    "    tree = MTree(metrics.dist_fft_numba, max_node_size=k, promote=promote, partition=partition)\n",
    "    tree.add_all(data)\n",
    "    return tree\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "\n",
    "        self.imgs_path = \"../data/imdb_wiki/\"\n",
    "        file_list = glob.glob(self.imgs_path + \"*\")\n",
    "        self.images = []\n",
    "        for class_path in file_list:\n",
    "            for dir_path in glob.glob(class_path + \"/*\"):\n",
    "                for img_path in glob.glob(dir_path + \"/*.jpg\"):\n",
    "                    self.images.append(img_path)\n",
    "\n",
    "    # Defining the length of the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    # Defining the method to get an item from the dataset\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.images[index]\n",
    "        image = Image.open(image_path)\n",
    "        image = transforms.functional.to_grayscale(image)\n",
    "\n",
    "        # Applying the transform\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image.squeeze().to('cpu').numpy()\n",
    "\n",
    "\n",
    "\n",
    "class CustomDatasetMStar(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "\n",
    "        self.imgs_path = \"../data/mstar/Padded_imgs/\"\n",
    "        file_list = glob.glob(self.imgs_path + \"*\")\n",
    "        self.data = []\n",
    "        for class_path in file_list:\n",
    "            class_name = class_path.split(\"/\")[-1]\n",
    "            for img_path in glob.glob(class_path + \"/*.JPG\"):\n",
    "                self.data.append([img_path, class_name])\n",
    "        #print(self.data)\n",
    "        self.class_map = {\"2S1\" : 0, \"BRDM_2\": 1, \"BTR_60\": 2, \"D7\": 3, \"SLICY\": 4, \"T62\": 5, \"ZIL131\": 6, \"ZSU_23_4\": 7}\n",
    "\n",
    "    # Defining the length of the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    # Defining the method to get an item from the dataset\n",
    "    def __getitem__(self, index):\n",
    "        data_path = self.data[index]\n",
    "        image = Image.open(data_path[0])\n",
    "        image = transforms.functional.to_grayscale(image)\n",
    "        class_id = self.class_map[data_path[1]]\n",
    "        # Applying the transform\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image.squeeze().to('cpu').numpy(), class_id\n",
    "\n",
    "def get_data(size):\n",
    "    transform = transforms.Compose([\n",
    "    transforms.Resize((size, size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    return CustomDataset(transform)\n",
    "\n",
    "def get_data_MStar(size):\n",
    "    transform = transforms.Compose([\n",
    "    transforms.Resize((size, size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    return CustomDatasetMStar(transform)\n",
    "\n",
    "def mtree_ncc_query_sample_size(max_node_size=12, image_size=32, k=7, runs=2, sample_sizes=[1]):\n",
    "    total_time_ncc = 0\n",
    "    total_time_mtree = 0\n",
    "    avg_times_ncc = []\n",
    "    avg_times_mtree = []\n",
    "\n",
    "    data = get_data_MStar(image_size)\n",
    "\n",
    "    print(f\"Average runtime of querying mtree and ncc for {k} NN over {runs} runs with image size {image_size} and max node size {max_node_size} and variable sample size\")\n",
    "    for i in range(len(sample_sizes)):\n",
    "        print(f\"NOW TRYING sample size: {sample_sizes[i]}\")\n",
    "        total_time_ncc = 0\n",
    "        total_time_mtree = 0\n",
    "\n",
    "        sample_indices = random.sample(range(len(data)), sample_sizes[i])\n",
    "        sampled_test_data = Subset(data, sample_indices)\n",
    "\n",
    "        testSample = [item[0] for item in sampled_test_data]\n",
    "        \n",
    "\n",
    "        tree = getMTree(testSample, max_node_size)\n",
    "\n",
    "        # trans = transforms.Compose([transforms.Resize(img_sizes[i])])\n",
    "        # t_MNIST_data = trans(MNIST_data)\n",
    "\n",
    "        # for img in MNIST_data:\n",
    "        #     img = trans(img)\n",
    "\n",
    "        for _ in range(runs):\n",
    "            index1 = np.random.randint(len(data))\n",
    "            #input1=input_dataset[index1][0].squeeze().to('cpu')\n",
    "            unseen_image = data[index1][0]\n",
    "\n",
    "            start_time = time.time()\n",
    "            arr = []\n",
    "            for j in range(len(testSample)):\n",
    "                result = ImageProducts.ncc_scaled(testSample[j], unseen_image)\n",
    "                arr.append(result)\n",
    "            \n",
    "            unseen_img_arr = np.array(arr)\n",
    "            #print(unseen_img_arr)\n",
    "            imgProd_max_index = np.argpartition(unseen_img_arr, -(k+1))[-(k+1):]\n",
    "            end_time = time.time()\n",
    "\n",
    "            total_time_ncc += end_time - start_time\n",
    "\n",
    "            start_time = time.time()\n",
    "            imgs = getKNearestNeighbours(tree, unseen_image, k+1)\n",
    "            end_time = time.time()\n",
    "            total_time_mtree += end_time - start_time\n",
    "\n",
    "        avg_ncc = total_time_ncc / runs\n",
    "        avg_mtree = total_time_mtree / runs\n",
    "        avg_times_ncc.append(avg_ncc)\n",
    "        avg_times_mtree.append(avg_mtree)\n",
    "\n",
    "        # with open(\"test_mtree_query_sample_sizes_avg_times_ncc_.txt\", \"w\") as file:\n",
    "        #     file.write(f\"avg times: {str(avg_times_ncc)}\")\n",
    "        \n",
    "        # with open(\"test_mtree_query_sample_sizes_avg_times_mtree_.txt\", \"w\") as file:\n",
    "        #     file.write(f\"avg times: {str(avg_times_mtree)}\")\n",
    "\n",
    "        print(f\"Average runtime of ncc search: {avg_ncc:.6f} seconds\")\n",
    "        print(f\"Average runtime of mtree search: {avg_mtree:.6f} seconds\")\n",
    "    # plot_data_mtree_ncc(x_axis=\"Sample size\", title=f\"Average runtime of finding {k} neighbours with image size {image_size} against sample sizes\", filename=\"test_mtree_query_sample_sizes.png\", \n",
    "    #                     varied_arr=sample_sizes, data1=avg_times_ncc, data2=avg_times_mtree, max_node_size=max_node_size)\n",
    "\n",
    "\n",
    "def mtree_init_sample_size(max_node_size=12, image_size=32, k=7, runs=2, sample_sizes=[1]):\n",
    "    total_time_mtree_init = 0\n",
    "    avg_times_mtree_init = []\n",
    "\n",
    "    data = get_data_MStar(image_size)\n",
    "\n",
    "    print(f\"Average runtime of initialising mtree over {runs} runs with max node size {max_node_size} and image size {image_size} and variable sample sizes\")\n",
    "\n",
    "    for i in range(len(sample_sizes)):\n",
    "        print(f\"NOW TRYING sample size: {sample_sizes[i]}\")\n",
    "        total_time_mtree_init = 0\n",
    "\n",
    "        sample_indices = random.sample(range(len(data)), sample_sizes[i])\n",
    "        sampled_test_data = Subset(data, sample_indices)\n",
    "\n",
    "        testSample = [item[0] for item in sampled_test_data]\n",
    "        #sampled_test_data[:,0]\n",
    "\n",
    "        for _ in range(runs):\n",
    "            start_time = time.time()\n",
    "            tree = getMTree(testSample, max_node_size)\n",
    "            end_time = time.time()\n",
    "            total_time_mtree_init += end_time - start_time\n",
    "            print(f\"Finished one run of mtree init...\")\n",
    "\n",
    "        \n",
    "        avg_mtree_init = total_time_mtree_init / runs\n",
    "        avg_times_mtree_init.append(avg_mtree_init)\n",
    "\n",
    "        \n",
    "        # with open(\"test_mtree_init_sample_sizes_avg_times_mtree_init.txt\", \"w\") as file:\n",
    "        #     file.write(f\"avg times: {str(avg_times_mtree_init)}\")\n",
    "\n",
    "        print(f\"Average runtime of mtree init: {avg_mtree_init:.6f} seconds\")\n",
    "    \n",
    "    # plot_data_mtree_init(x_axis=\"Sample size\", title=f\"Average runtime of initialising mtree with image size {image_size}, max node size {max_node_size} against sample sizes\", filename=\"test_mtree_init_sample_sizes.png\", \n",
    "    #                     varied_arr=sample_sizes, data=avg_times_mtree_init, max_node_size=max_node_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c5946879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average runtime of querying mtree and ncc for 7 NN over 10 runs with image size 368 and max node size 15 and variable sample size\n",
      "NOW TRYING sample size: 10\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ImageProducts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[172]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 9466 samples\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# note MStar is 368 by 368...\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mmtree_ncc_query_sample_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_node_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m368\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mruns\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[171]\u001b[39m\u001b[32m, line 168\u001b[39m, in \u001b[36mmtree_ncc_query_sample_size\u001b[39m\u001b[34m(max_node_size, image_size, k, runs, sample_sizes)\u001b[39m\n\u001b[32m    166\u001b[39m arr = []\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(testSample)):\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m     result = \u001b[43mImageProducts\u001b[49m.ncc_scaled(testSample[j], unseen_image)\n\u001b[32m    169\u001b[39m     arr.append(result)\n\u001b[32m    171\u001b[39m unseen_img_arr = np.array(arr)\n",
      "\u001b[31mNameError\u001b[39m: name 'ImageProducts' is not defined"
     ]
    }
   ],
   "source": [
    "# 9466 samples\n",
    "# note MStar is 368 by 368...\n",
    "\n",
    "mtree_ncc_query_sample_size(max_node_size=15, image_size=368, k=7, runs=10, sample_sizes=[10, 100, 1000, 2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d04ab0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_name': '0012296.jpg', 'height': 512, 'width': 512, 'id': 0}\n",
      "10492\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../data/SARDet_100k/SARDet_100K/Annotations/val.json\") as val_annotations:\n",
    "    mappings = json.load(val_annotations)\n",
    "\n",
    "print(mappings[\"images\"][0])\n",
    "print(len(mappings[\"images\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a10d48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@inproceedings{li2024sardet100k,\n",
    "\ttitle={SARDet-100K: Towards Open-Source Benchmark and ToolKit for Large-Scale SAR Object Detection}, \n",
    "\tauthor={Yuxuan Li and Xiang Li and Weijie Li and Qibin Hou and Li Liu and Ming-Ming Cheng and Jian Yang},\n",
    "\tyear={2024},\n",
    "\tbooktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems (NeurIPS)},\n",
    "}\n",
    "\n",
    "@article{zhang2025rsar,\n",
    "  title={RSAR: Restricted State Angle Resolver and Rotated SAR Benchmark},\n",
    "  author={Zhang, Xin and Yang, Xue and Li, Yuxuan and Yang, Jian and Cheng, Ming-Ming and Li, Xiang},\n",
    "  journal={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},\n",
    "  year={2025}\n",
    "}\n",
    "\n",
    "@article{dai2024denodet,\n",
    "\ttitle={DenoDet: Attention as Deformable Multi-Subspace Feature Denoising for Target Detection in SAR Images},\n",
    "\tauthor={Dai, Yimian and Zou, Minrui and Li, Yuxuan and Li, Xiang and Ni, Kang and Yang, Jian},\n",
    "\tjournal={arXiv preprint arXiv:2406.02833},\n",
    "\tyear={2024}\n",
    "}\n",
    "'''\n",
    "import json\n",
    "# TODO look at train/val/test.json format and extract out the category id and the id to class mapping at the v end.\n",
    "\n",
    "\n",
    "class CustomDatasetSARDet_100k(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        \n",
    "        with open(\"../data/SARDet_100k/SARDet_100K/Annotations/test.json\") as annotations:\n",
    "            test_mapping = json.load(annotations)\n",
    "        with open(\"../data/SARDet_100k/SARDet_100K/Annotations/train.json\") as annotations:\n",
    "            train_mapping = json.load(annotations)\n",
    "        with open(\"../data/SARDet_100k/SARDet_100K/Annotations/val.json\") as annotations:\n",
    "            val_mapping = json.load(annotations)\n",
    "        \n",
    "        self.imgs_path = \"../data/SARDet_100k/SARDet_100K/JPEGImages/\"\n",
    "\n",
    "        test_path = self.imgs_path + \"test/\"\n",
    "        train_path = self.imgs_path + \"train/\"\n",
    "        val_path = self.imgs_path + \"val/\"\n",
    "\n",
    "        for i in range(len(test_mapping[\"images\"])):\n",
    "            img_path = test_path + test_mapping[\"images\"][i][\"file_name\"]\n",
    "            cat_id = test_mapping[\"annotations\"][i][\"category_id\"]\n",
    "            cat_name = test_mapping[\"categories\"][int(cat_id)][\"name\"]\n",
    "            self.data.append([img_path, cat_name])\n",
    "\n",
    "        for i in range(len(train_mapping[\"images\"])):\n",
    "            img_path = train_path + train_mapping[\"images\"][i][\"file_name\"]\n",
    "            cat_id = train_mapping[\"annotations\"][i][\"category_id\"]\n",
    "            cat_name = train_mapping[\"categories\"][int(cat_id)][\"name\"]\n",
    "            self.data.append([img_path, cat_name])\n",
    "        \n",
    "        for i in range(len(val_mapping[\"images\"])):\n",
    "            img_path = val_path + val_mapping[\"images\"][i][\"file_name\"]\n",
    "            cat_id = val_mapping[\"annotations\"][i][\"category_id\"]\n",
    "            cat_name = val_mapping[\"categories\"][int(cat_id)][\"name\"]\n",
    "            self.data.append([img_path, cat_name])\n",
    "\n",
    "        # file_list = glob.glob(self.imgs_path + \"*\")\n",
    "        # self.data = []\n",
    "\n",
    "        # # with open(\"../data/SARDet_100k/SARDet_100K/mapping.json\") as annotations:\n",
    "        # #     mappings = json.load(annotations)\n",
    "\n",
    "        # for dir_path in file_list:\n",
    "        #     for img_path in glob.glob(dir_path + \"/*.png\"):\n",
    "        #         # self.data.append([img_path, mappings[img_path.split(\"/\")[-1]]])\n",
    "        #         self.data.append([img_path, \"yippee\"])\n",
    "        #     for img_path in glob.glob(dir_path + \"/*.jpg\"):\n",
    "        #         # self.data.append([img_path, mappings[img_path.split(\"/\")[-1]]])\n",
    "        #         self.data.append([img_path, \"yippee\"])\n",
    "        \n",
    "\n",
    "    # Defining the length of the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    # Defining the method to get an item from the dataset\n",
    "    def __getitem__(self, index):\n",
    "        data_path = self.data[index]\n",
    "        image = Image.open(data_path[0])\n",
    "        image = transforms.functional.to_grayscale(image)\n",
    "        # class_id = self.class_map[data_path[1]]\n",
    "        class_id = data_path[1]\n",
    "        # Applying the transform\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image.squeeze().to('cpu').numpy(), class_id\n",
    "\n",
    "def get_data_SARDet_100k(size):\n",
    "    transform = transforms.Compose([\n",
    "    transforms.Resize((size, size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    return CustomDatasetSARDet_100k(transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a83143d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root tag: annotation\n",
      "KU_HH_15_80_325790.tif\n",
      "Car\n",
      "Medium_Car\n",
      "GT\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "tree = ET.parse('/home/jovyan/data/ATRNet-STAR/EOC_azimuth/test/Buick_Excelle_GT/KU_HH_15_80_325790.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "print(\"Root tag:\", root.tag)\n",
    "\n",
    "\n",
    "img_path = root.find('filename').text\n",
    "broad_class = root.find('object').find('class').text\n",
    "subclass = root.find('object').find('subclass').text\n",
    "subclass_type = root.find('object').find('type').text.split(\"_\")[-1]\n",
    "\n",
    "print(img_path)\n",
    "print(broad_class)\n",
    "print(subclass)\n",
    "print(subclass_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3688569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "misc{liu2025atrnet,\n",
    "    title={{ATRNet-STAR}: A Large Dataset and Benchmark Towards Remote Sensing Object Recognition in the Wild}, \n",
    "    author={Yongxiang Liu and Weijie Li and Li Liu and Jie Zhou and Bowen Peng and Yafei Song and Xuying Xiong and Wei Yang and Tianpeng Liu and Zhen Liu and Xiang Li},\n",
    "    year={2025},\n",
    "    eprint={2501.13354},\n",
    "    archivePrefix={arXiv},\n",
    "    primaryClass={cs.CV},\n",
    "    url={https://arxiv.org/abs/2501.13354},\n",
    "}\n",
    "\n",
    "@ARTICLE{li2025saratr,\n",
    "  author={Li, Weijie and Yang, Wei and Hou, Yuenan and Liu, Li and Liu, Yongxiang and Li, Xiang},\n",
    "  journal={IEEE Transactions on Image Processing}, \n",
    "  title={SARATR-X: Toward Building a Foundation Model for SAR Target Recognition}, \n",
    "  year={2025},\n",
    "  volume={34},\n",
    "  number={},\n",
    "  pages={869-884},\n",
    "  doi={10.1109/TIP.2025.3531988}}\n",
    "\n",
    "@ARTICLE{li2024predicting,\n",
    "  title = {Predicting gradient is better: Exploring self-supervised learning for SAR ATR with a joint-embedding predictive architecture},\n",
    "  journal = {ISPRS Journal of Photogrammetry and Remote Sensing},\n",
    "  volume = {218},\n",
    "  pages = {326-338},\n",
    "  year = {2024},\n",
    "  issn = {0924-2716},\n",
    "  doi = {https://doi.org/10.1016/j.isprsjprs.2024.09.013},\n",
    "  url = {https://www.sciencedirect.com/science/article/pii/S0924271624003514},\n",
    "  author = {Li, Weijie and Yang, Wei and Liu, Tianpeng and Hou, Yuenan and Li, Yuxuan and Liu, Zhen and Liu, Yongxiang and Liu, Li}}\n",
    "\n",
    "Downloads last month\n",
    "167\n",
    "System\n",
    "'''\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "\n",
    "class CustomDatasetATRNetSTAR(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        # Check if I can test the azimuths.... if not j try smt else idk\n",
    "        self.imgs_path = \"../data/ATRNet-STAR/EOC_azimuth/\"\n",
    "        file_list = glob.glob(self.imgs_path + \"*\")\n",
    "\n",
    "        for dir_path in file_list:\n",
    "            for cat in glob.glob(dir_path + \"/\"):\n",
    "                for xml_file_path in glob.glob(cat + \"/*.xml\"):\n",
    "                    tree = ET.parse(xml_file_path)\n",
    "                    root = tree.getroot()\n",
    "                    img_path = root.find('filename').text\n",
    "                    broad_class = root.find('object').find('class').text\n",
    "                    subclass = root.find('object').find('subclass').text\n",
    "                    subclass_type = root.find('object').find('type').text.split(\"_\")[-1]\n",
    "                    self.data.append([img_path, broad_class, subclass, subclass_type])\n",
    "    \n",
    "\n",
    "        # file_list = glob.glob(self.imgs_path + \"*\")\n",
    "        # self.data = []\n",
    "\n",
    "        # # with open(\"../data/SARDet_100k/SARDet_100K/mapping.json\") as annotations:\n",
    "        # #     mappings = json.load(annotations)\n",
    "\n",
    "        # for dir_path in file_list:\n",
    "        #     for img_path in glob.glob(dir_path + \"/*.png\"):\n",
    "        #         # self.data.append([img_path, mappings[img_path.split(\"/\")[-1]]])\n",
    "        #         self.data.append([img_path, \"yippee\"])\n",
    "        #     for img_path in glob.glob(dir_path + \"/*.jpg\"):\n",
    "        #         # self.data.append([img_path, mappings[img_path.split(\"/\")[-1]]])\n",
    "        #         self.data.append([img_path, \"yippee\"])\n",
    "        \n",
    "\n",
    "    # Defining the length of the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    # Defining the method to get an item from the dataset\n",
    "    def __getitem__(self, index):\n",
    "        data_path = self.data[index]\n",
    "        image = Image.open(data_path[0])\n",
    "        image = transforms.functional.to_grayscale(image)\n",
    "        # class_id = self.class_map[data_path[1]]\n",
    "        broad_class = data_path[1]\n",
    "        subclass = data_path[2]\n",
    "        subclass_type = data_path[3]\n",
    "        # Applying the transform\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image.squeeze().to('cpu').numpy(), broad_class, subclass, subclass_type\n",
    "\n",
    "\n",
    "\n",
    "def get_data_ATRNetSTAR(size):\n",
    "    transform = transforms.Compose([\n",
    "    transforms.Resize((size, size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    return CustomDatasetATRNetSTAR(transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f53085e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116598\n"
     ]
    }
   ],
   "source": [
    "data = get_data_SARDet_100k(300)\n",
    "print(len(data))\n",
    "sample_indices = random.sample(range(len(data)), 100)\n",
    "sampled_test_data = Subset(data, sample_indices)\n",
    "\n",
    "testSample = [item[0] for item in sampled_test_data]\n",
    "classes = [item[1] for item in sampled_test_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00583247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aircraft\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index1 = np.random.randint(len(testSample))\n",
    "#index2 = np.random.randint(len(testSample))\n",
    "#input2=input_dataset[index2][0].squeeze().to('cpu')\n",
    "print(classes[index1])\n",
    "plt.imshow(testSample[index1], cmap='grey')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d96f5a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9466\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      8\u001b[39m classes = [item[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m sampled_test_data]\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# class_map = {\"2S1\" : 0, \"BRDM_2\": 1, \"BTR_60\": 2, \"D7\": 3, \"SLICY\": 4, \"T62\": 5, \"ZIL131\": 6, \"ZSU_23_4\": 7}\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m tree = \u001b[43mgetMTree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestSample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m12\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m index1 = random.choice(sample_indices)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m#input1=input_dataset[index1][0].squeeze().to('cpu')\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mgetMTree\u001b[39m\u001b[34m(data, k, promote, partition, d)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgetMTree\u001b[39m(data, k, promote=mtree.M_LB_DIST_confirmed, partition=mtree.generalized_hyperplane, d=metrics.distance):\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# k: desired number of nearest neighbours\u001b[39;00m\n\u001b[32m     40\u001b[39m     tree = MTree(d, max_node_size=k, promote=promote, partition=partition)\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[43mtree\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tree\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mtree/mtree.py:241\u001b[39m, in \u001b[36mMTree.add_all\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m    239\u001b[39m \u001b[38;5;66;03m#TODO: implement using the bulk-loading algorithm\u001b[39;00m\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mtree/mtree.py:232\u001b[39m, in \u001b[36mMTree.add\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj):\n\u001b[32m    229\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    230\u001b[39m \u001b[33;03m    Add an object into the M-tree\u001b[39;00m\n\u001b[32m    231\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mself\u001b[39m.size += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mtree/mtree.py:523\u001b[39m, in \u001b[36mLeafNode.add\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    521\u001b[39m     \u001b[38;5;28mself\u001b[39m.entries.add(new_entry)\n\u001b[32m    522\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m     \u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_root() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parent_node\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mtree/mtree.py:741\u001b[39m, in \u001b[36msplit\u001b[39m\u001b[34m(existing_node, entry, d)\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;66;03m#It is guaranteed that the current routing entry of the split node\u001b[39;00m\n\u001b[32m    736\u001b[39m \u001b[38;5;66;03m#(i.e. existing_node.parent_entry) is the one distance_to_parent\u001b[39;00m\n\u001b[32m    737\u001b[39m \u001b[38;5;66;03m#refers to in the entries (including the entry parameter). \u001b[39;00m\n\u001b[32m    738\u001b[39m \u001b[38;5;66;03m#Promote can therefore use distance_to_parent of the entries.\u001b[39;00m\n\u001b[32m    739\u001b[39m routing_object1, routing_object2 = \\\n\u001b[32m    740\u001b[39m     mtree.promote(all_entries, existing_node.parent_entry, d)\n\u001b[32m--> \u001b[39m\u001b[32m741\u001b[39m entries1, entries2 = \u001b[43mmtree\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpartition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_entries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    742\u001b[39m \u001b[43m                                     \u001b[49m\u001b[43mrouting_object1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    743\u001b[39m \u001b[43m                                     \u001b[49m\u001b[43mrouting_object2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    744\u001b[39m \u001b[43m                                     \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    745\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m entries1 \u001b[38;5;129;01mand\u001b[39;00m entries2, \u001b[33m\"\u001b[39m\u001b[33mError during split operation. All the entries have been assigned to one routing_objects and none to the other! Should never happen since at least the routing objects are assigned to their corresponding set of entries\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m#must save the old entry of the existing node because it will have\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[38;5;66;03m#to be removed from the parent node later\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mtree/mtree.py:157\u001b[39m, in \u001b[36mgeneralized_hyperplane\u001b[39m\u001b[34m(entries, routing_object1, routing_object2, d)\u001b[39m\n\u001b[32m    155\u001b[39m partition = (\u001b[38;5;28mset\u001b[39m(), \u001b[38;5;28mset\u001b[39m())\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m entries:\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m     partition[\u001b[43md\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouting_object1\u001b[49m\u001b[43m)\u001b[49m > \\\n\u001b[32m    158\u001b[39m                      d(entry.obj, routing_object2)].add(entry)\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partition[\u001b[32m0\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partition[\u001b[32m1\u001b[39m]:\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m#all objects have been put on the same routing_object\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m#can only happen if all objects are the same point (d() always 0)\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m#fix by splitting the group in two\u001b[39;00m\n\u001b[32m    164\u001b[39m     partition = (\u001b[38;5;28mset\u001b[39m(islice(entries, \u001b[38;5;28mlen\u001b[39m(entries)//\u001b[32m2\u001b[39m)),\n\u001b[32m    165\u001b[39m                  \u001b[38;5;28mset\u001b[39m(islice(entries, \u001b[38;5;28mlen\u001b[39m(entries)//\u001b[32m2\u001b[39m, \u001b[38;5;28mlen\u001b[39m(entries))))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/helpers/MetricUtilities.py:14\u001b[39m, in \u001b[36mdistance\u001b[39m\u001b[34m(img1, img2)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdistance\u001b[39m(img1, img2):\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m#print(img1)\u001b[39;00m\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m#print(img2)\u001b[39;00m\n\u001b[32m     13\u001b[39m     \u001b[38;5;66;03m#print(min(ImageProducts.ncc(img1, img2), 1))\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     ncc = \u001b[38;5;28mmin\u001b[39m(\u001b[43mImageProducts\u001b[49m\u001b[43m.\u001b[49m\u001b[43mncc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg2\u001b[49m\u001b[43m)\u001b[49m, \u001b[32m1\u001b[39m)\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# ncc = max(ncc, 0)\u001b[39;00m\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m#print(math.acos(ImageProducts.ncc(img1, img2)))\u001b[39;00m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (math.acos(ncc) / (math.pi))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/data_processing/ImageProducts.py:162\u001b[39m, in \u001b[36mncc\u001b[39m\u001b[34m(mainImg, tempImg)\u001b[39m\n\u001b[32m    159\u001b[39m mainImg = np.asarray(mainImg, np.single)  \u001b[38;5;66;03m# Setting data types of array\u001b[39;00m\n\u001b[32m    160\u001b[39m tempImg = np.asarray(tempImg, np.single)\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m corr = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatchTemplate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmainImg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtempImg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTM_CCORR_NORMED\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(corr)\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m max_val\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "k=7\n",
    "data = get_data_MStar(368)\n",
    "print(len(data))\n",
    "sample_indices = random.sample(range(len(data)), 100)\n",
    "sampled_test_data = Subset(data, sample_indices)\n",
    "\n",
    "testSample = [item[0] for item in sampled_test_data]\n",
    "classes = [item[1] for item in sampled_test_data]\n",
    "\n",
    "# class_map = {\"2S1\" : 0, \"BRDM_2\": 1, \"BTR_60\": 2, \"D7\": 3, \"SLICY\": 4, \"T62\": 5, \"ZIL131\": 6, \"ZSU_23_4\": 7}\n",
    "\n",
    "tree = getMTree(testSample, 12)\n",
    "\n",
    "index1 = random.choice(sample_indices)\n",
    "#input1=input_dataset[index1][0].squeeze().to('cpu')\n",
    "unseen_image = data[index1][0]\n",
    "unseen_image_class = data[index1][1]\n",
    "\n",
    "arr = []\n",
    "for j in range(len(testSample)):\n",
    "    result = ImageProducts.ncc_scaled(testSample[j], unseen_image)\n",
    "    arr.append(result)\n",
    "\n",
    "unseen_img_arr = np.array(arr)\n",
    "#print(unseen_img_arr)\n",
    "imgProd_max_index = np.argpartition(unseen_img_arr, -(k+1))[-(k+1):]\n",
    "\n",
    "num_same_class = 0\n",
    "\n",
    "print(f\"Unseen img class: {unseen_image_class}\")\n",
    "for i in imgProd_max_index:\n",
    "    img_class = classes[i]\n",
    "    print(f\"Index {i}, Class {img_class}\")\n",
    "    if (img_class == unseen_image_class):\n",
    "        num_same_class += 1\n",
    "\n",
    "print(num_same_class)\n",
    "\n",
    "\n",
    "imgs = getKNearestNeighbours(tree, unseen_image, k+1)\n",
    "\n",
    "\n",
    "def imgs_to_indices(img_arr, testSample):\n",
    "    ind_arr = []\n",
    "    for img in img_arr:\n",
    "        for i in range(len(testSample)):\n",
    "            if (metrics.distance(img, testSample[i]) < 0.00001):\n",
    "                ind_arr.append(i)\n",
    "                break\n",
    "    \n",
    "    return ind_arr\n",
    "\n",
    "ind_arr = imgs_to_indices(imgs, testSample)\n",
    "print(ind_arr)\n",
    "print(imgProd_max_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0024020e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9466\n",
      "Unseen img class: 2\n",
      "Index 2, Class 1\n",
      "Index 56, Class 6\n",
      "Index 95, Class 2\n",
      "Index 57, Class 0\n",
      "Index 46, Class 2\n",
      "Index 69, Class 0\n",
      "Index 93, Class 7\n",
      "Index 58, Class 2\n",
      "3\n",
      "[58, 93, 69, 46, 57, 95, 56, 2]\n",
      "[58, 93, 69, 46, 57, 95, 56, 2]\n",
      "[ 2 56 95 57 46 69 93 58]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def ncc(mainImg, tempImg) -> float:\n",
    "    \"\"\"\n",
    "    :param mainImg: Main image to be scanned\n",
    "    :param tempImg: Template image to be scanned over the main\n",
    "    :return: Max value of the ncc\n",
    "\n",
    "    Applies NCC of the template image over the main image and returns the max value obtained.\n",
    "    When the template image kernel exceeds the bounds, wraps to the other side of the main image\n",
    "    \"\"\"\n",
    "    if np.count_nonzero(mainImg) == 0:\n",
    "        if np.count_nonzero(tempImg) == 0:\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "    mainImg = np.pad(mainImg, max(len(mainImg), len(mainImg[0])),\n",
    "                     'wrap')  # Padding the main image with wrapped values to simulate wrapping\n",
    "\n",
    "    mainImg = np.asarray(mainImg, np.single)  # Setting data types of array\n",
    "    tempImg = np.asarray(tempImg, np.single)\n",
    "\n",
    "    corr = cv2.matchTemplate(mainImg, tempImg, cv2.TM_CCORR_NORMED)\n",
    "\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(corr)\n",
    "\n",
    "    return max_val\n",
    "\n",
    "def ncc_scaled(mainImg, tempImg) -> float:\n",
    "    \"\"\"\n",
    "    :param mainImg: Main image to be scanned\n",
    "    :param tempImg: Template image to be scanned over the main\n",
    "    :return: Max value of the ncc, with scaled bounds of [-1,1]\n",
    "    \"\"\"\n",
    "    return ncc(mainImg, tempImg) * 2 - 1\n",
    "\n",
    "\n",
    "class CustomDatasetMStar(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "\n",
    "        self.imgs_path = \"../data/mstar/Padded_imgs/\"\n",
    "        file_list = glob.glob(self.imgs_path + \"*\")\n",
    "        self.data = []\n",
    "        for class_path in file_list:\n",
    "            class_name = class_path.split(\"/\")[-1]\n",
    "            for img_path in glob.glob(class_path + \"/*.JPG\"):\n",
    "                self.data.append([img_path, class_name])\n",
    "        #print(self.data)\n",
    "        self.class_map = {\"2S1\" : 0, \"BRDM_2\": 1, \"BTR_60\": 2, \"D7\": 3, \"SLICY\": 4, \"T62\": 5, \"ZIL131\": 6, \"ZSU_23_4\": 7}\n",
    "\n",
    "    # Defining the length of the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    # Defining the method to get an item from the dataset\n",
    "    def __getitem__(self, index):\n",
    "        data_path = self.data[index]\n",
    "        image = Image.open(data_path[0])\n",
    "        image = transforms.functional.to_grayscale(image)\n",
    "        class_id = self.class_map[data_path[1]]\n",
    "        # Applying the transform\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image.squeeze().to('cpu').numpy(), class_id\n",
    "\n",
    "k=7\n",
    "data = get_data_MStar(16)\n",
    "print(len(data))\n",
    "sample_indices = random.sample(range(len(data)), 100)\n",
    "sampled_test_data = Subset(data, sample_indices)\n",
    "\n",
    "testSample = [item[0] for item in sampled_test_data]\n",
    "classes = [item[1] for item in sampled_test_data]\n",
    "\n",
    "# class_map = {\"2S1\" : 0, \"BRDM_2\": 1, \"BTR_60\": 2, \"D7\": 3, \"SLICY\": 4, \"T62\": 5, \"ZIL131\": 6, \"ZSU_23_4\": 7}\n",
    "\n",
    "tree = getMTreeFFTNumba(testSample, 12)\n",
    "tree_mst = getMTreeFFTNumba(testSample, 12, promote=mtree.MST_promotion, partition=mtree.MST_partition)\n",
    "\n",
    "index1 = random.choice(sample_indices)\n",
    "#input1=input_dataset[index1][0].squeeze().to('cpu')\n",
    "unseen_image = data[index1][0]\n",
    "unseen_image_class = data[index1][1]\n",
    "\n",
    "arr = []\n",
    "for j in range(len(testSample)):\n",
    "    result = ncc_scaled(testSample[j], unseen_image)\n",
    "    arr.append(result)\n",
    "\n",
    "unseen_img_arr = np.array(arr)\n",
    "#print(unseen_img_arr)\n",
    "imgProd_max_index = np.argpartition(unseen_img_arr, -(k+1))[-(k+1):]\n",
    "\n",
    "num_same_class = 0\n",
    "\n",
    "print(f\"Unseen img class: {unseen_image_class}\")\n",
    "for i in imgProd_max_index:\n",
    "    img_class = classes[i]\n",
    "    print(f\"Index {i}, Class {img_class}\")\n",
    "    if (img_class == unseen_image_class):\n",
    "        num_same_class += 1\n",
    "\n",
    "print(num_same_class)\n",
    "\n",
    "\n",
    "imgs = getKNearestNeighbours(tree, unseen_image, k+1)\n",
    "imgs_mst = getKNearestNeighbours(tree_mst, unseen_image, k+1)\n",
    "\n",
    "def imgs_to_indices(img_arr, testSample):\n",
    "    ind_arr = []\n",
    "    for img in img_arr:\n",
    "        for i in range(len(testSample)):\n",
    "            if (metrics.dist_fft_numba(img, testSample[i]) < 0.0000001):\n",
    "                ind_arr.append(i)\n",
    "                break\n",
    "    \n",
    "    return ind_arr\n",
    "\n",
    "ind_arr = imgs_to_indices(imgs, testSample)\n",
    "ind_arr_mst = imgs_to_indices(imgs_mst, testSample)\n",
    "print(ind_arr_mst)\n",
    "print(ind_arr)\n",
    "print(imgProd_max_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4cfdd451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9925995469093323\n",
      "0.99259925\n",
      "0.99259925\n"
     ]
    }
   ],
   "source": [
    "import scipy.fft\n",
    "import math\n",
    "\n",
    "def ncc(mainImg, tempImg) -> float:\n",
    "    \"\"\"\n",
    "    :param mainImg: Main image to be scanned\n",
    "    :param tempImg: Template image to be scanned over the main\n",
    "    :return: Max value of the ncc\n",
    "\n",
    "    Applies NCC of the template image over the main image and returns the max value obtained.\n",
    "    When the template image kernel exceeds the bounds, wraps to the other side of the main image\n",
    "    \"\"\"\n",
    "    if np.count_nonzero(mainImg) == 0:\n",
    "        if np.count_nonzero(tempImg) == 0:\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "    mainImg = np.pad(mainImg, max(len(mainImg), len(mainImg[0])),\n",
    "                     'wrap')  # Padding the main image with wrapped values to simulate wrapping\n",
    "\n",
    "    mainImg = np.asarray(mainImg, np.single)  # Setting data types of array\n",
    "    tempImg = np.asarray(tempImg, np.single)\n",
    "\n",
    "    corr = cv2.matchTemplate(mainImg, tempImg, cv2.TM_CCORR_NORMED)\n",
    "\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(corr)\n",
    "\n",
    "    return max_val\n",
    "\n",
    "def ncc_unnormed(mainImg, tempImg) -> float:\n",
    "    \"\"\"\n",
    "    :param mainImg: Main image to be scanned\n",
    "    :param tempImg: Template image to be scanned over the main\n",
    "    :return: Max value of the ncc\n",
    "\n",
    "    Applies NCC of the template image over the main image and returns the max value obtained.\n",
    "    When the template image kernel exceeds the bounds, wraps to the other side of the main image\n",
    "    \"\"\"\n",
    "    if np.count_nonzero(mainImg) == 0:\n",
    "        if np.count_nonzero(tempImg) == 0:\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "    mainImg = np.pad(mainImg, max(len(mainImg), len(mainImg[0])),\n",
    "                     'wrap')  # Padding the main image with wrapped values to simulate wrapping\n",
    "\n",
    "    mainImg = np.asarray(mainImg, np.single)  # Setting data types of array\n",
    "    tempImg = np.asarray(tempImg, np.single)\n",
    "\n",
    "    corr = cv2.matchTemplate(mainImg, tempImg, cv2.TM_CCORR)\n",
    "\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(corr)\n",
    "\n",
    "    return max_val\n",
    "\n",
    "dataset = get_data_MStar(300)\n",
    "\n",
    "sample_indices = random.sample(range(len(data)), 100)\n",
    "sampled_test_data = Subset(data, sample_indices)\n",
    "\n",
    "testSample = [item[0] for item in sampled_test_data]\n",
    "index1 = np.random.randint(len(data))\n",
    "index2 = np.random.randint(len(testSample))\n",
    "unseen_image = data[index1][0]\n",
    "\n",
    "\n",
    "test_img = testSample[index2]\n",
    "test_img2 = unseen_image\n",
    "m = test_img.shape[0]\n",
    "\n",
    "ncc_score_un = ncc_unnormed(test_img, test_img2)\n",
    "ncc_score = ncc(test_img, test_img2)\n",
    "print(ncc_score)\n",
    "\n",
    "\n",
    "def ncc_fft(mainImg, tempImg):\n",
    "    A = scipy.fft.fft2(mainImg)\n",
    "    B = scipy.fft.fft2(tempImg)\n",
    "\n",
    "    Z = scipy.fft.ifft2(np.conj(A) * B).real\n",
    "\n",
    "    auto_A = scipy.fft.ifft2(np.conj(A) * A).real\n",
    "    auto_B = scipy.fft.ifft2(np.conj(B) * B).real\n",
    "    auto_A = np.maximum(auto_A, 0.0001)\n",
    "    auto_B = np.maximum(auto_B, 0.0001)\n",
    "    auto_A_sqrt = np.sqrt(auto_A)\n",
    "    auto_B_sqrt = np.sqrt(auto_B)\n",
    "    denom = np.multiply(auto_A_sqrt, auto_B_sqrt).max() # (THIS WORKS.) (Basically uhm so the normalization amt should be the same throughout? I'm not v sure why this works...)\n",
    "\n",
    "    return np.divide(Z, denom).max()\n",
    "\n",
    "#print(ncc_fft(test_img, test_img2))\n",
    "\n",
    "def ncc_naive(mainImg, tempImg):\n",
    "    if np.count_nonzero(mainImg) == 0:\n",
    "        if np.count_nonzero(tempImg) == 0:\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "    mainImg = np.pad(mainImg, max(len(mainImg), len(mainImg[0])),\n",
    "                     'wrap')  # Padding the main image with wrapped values to simulate wrapping\n",
    "\n",
    "    mainImg = np.asarray(mainImg, np.single)  # Setting data types of array\n",
    "    tempImg = np.asarray(tempImg, np.single)\n",
    "    m = tempImg.shape[0]\n",
    "    ncc_arr = np.ones((2*m, 2*m))\n",
    "    for i in range(2 * m):\n",
    "        for j in range(2 * m):\n",
    "            sum = 0\n",
    "            sum_norm_main = 0\n",
    "            sum_norm_temp = 0\n",
    "            for x in range(m):\n",
    "                for y in range(m):\n",
    "                    sum += mainImg[x + i][y + j] * tempImg[x][y]\n",
    "                    sum_norm_main += (mainImg[x+i][y+j])**2\n",
    "                    sum_norm_temp += (tempImg[x][y])**2\n",
    "            \n",
    "            ncc_arr[i][j] = (sum) / (math.sqrt(sum_norm_main * sum_norm_temp))\n",
    "    \n",
    "    return ncc_arr.max()\n",
    "\n",
    "def ncc_rfft(mainImg, tempImg):\n",
    "    A = scipy.fft.rfft2(mainImg)\n",
    "    B = scipy.fft.rfft2(tempImg)\n",
    "\n",
    "    Z = scipy.fft.irfft2(np.conj(A) * B).real\n",
    "\n",
    "    auto_A = scipy.fft.irfft2(np.conj(A) * A).real.max()\n",
    "    auto_B = scipy.fft.irfft2(np.conj(B) * B).real.max()\n",
    "    auto_A = np.maximum(auto_A, 0.0001)\n",
    "    auto_B = np.maximum(auto_B, 0.0001)\n",
    "    auto_A_sqrt = np.sqrt(auto_A)\n",
    "    auto_B_sqrt = np.sqrt(auto_B)\n",
    "    denom = np.multiply(auto_A_sqrt, auto_B_sqrt).max() # (THIS WORKS.) (Basically uhm so the normalization amt should be the same throughout? I'm not v sure why this works...)\n",
    "\n",
    "    return np.divide(Z, denom).max()\n",
    "\n",
    "print(ncc_rfft(test_img, test_img2))\n",
    "print(ncc_fft(test_img, test_img2))\n",
    "\n",
    "# for i in range(100):\n",
    "#     sample_indices = random.sample(range(len(data)), 100)\n",
    "#     sampled_test_data = Subset(data, sample_indices)\n",
    "\n",
    "#     testSample = [item[0] for item in sampled_test_data]\n",
    "#     index1 = np.random.randint(len(data))\n",
    "#     index2 = np.random.randint(len(testSample))\n",
    "#     unseen_image = data[index1][0]\n",
    "\n",
    "\n",
    "#     test_img = testSample[index2]\n",
    "#     test_img2 = unseen_image\n",
    "#     m = test_img.shape[0]\n",
    "\n",
    "#     ncc_score = ncc(test_img, test_img2)\n",
    "#     ncc_fft_score = ncc_fft(test_img, test_img2)\n",
    "#     ncc_rfft_score = ncc_rfft(test_img, test_img2)\n",
    "#     if (abs(ncc_score - ncc_fft_score) > 0.00001 or abs(ncc_score - ncc_rfft_score) > 0.00001):\n",
    "#         print(ncc_score)\n",
    "#         print(ncc_fft_score)\n",
    "#         print(ncc_rfft_score)\n",
    "\n",
    "# print(ncc_naive(test_img, test_img2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08d0587",
   "metadata": {},
   "source": [
    "## TEST NUMBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ab39c33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba as nb\n",
    "\n",
    "@nb.njit\n",
    "def ncc_fft_numba(mainImg, tempImg):\n",
    "    A = scipy.fft.fft2(mainImg)\n",
    "    B = scipy.fft.fft2(tempImg)\n",
    "\n",
    "    Z = scipy.fft.ifft2(np.conj(A) * B).real\n",
    "    # IT'S OK UP TO THIS POINT!!\n",
    "\n",
    "    auto_A = scipy.fft.ifft2(np.conj(A) * A).real\n",
    "    auto_B = scipy.fft.ifft2(np.conj(B) * B).real\n",
    "    auto_A = np.maximum(auto_A, 0.0001)\n",
    "    auto_B = np.maximum(auto_B, 0.0001)\n",
    "    auto_A_sqrt = np.sqrt(auto_A)\n",
    "    auto_B_sqrt = np.sqrt(auto_B)\n",
    "    denom = np.multiply(auto_A_sqrt, auto_B_sqrt).max()\n",
    "\n",
    "    return np.divide(Z, denom).max()\n",
    "\n",
    "@nb.njit\n",
    "def ncc_rfft_numba(mainImg, tempImg):\n",
    "    A = scipy.fft.rfft2(mainImg)\n",
    "    B = scipy.fft.rfft2(tempImg)\n",
    "\n",
    "    Z = scipy.fft.irfft2(np.conj(A) * B).real\n",
    "\n",
    "    auto_A = scipy.fft.irfft2((np.conj(A) * A).real)\n",
    "    auto_B = scipy.fft.irfft2((np.conj(B) * B).real)\n",
    "    auto_A = np.maximum(auto_A, 0.0001)\n",
    "    auto_B = np.maximum(auto_B, 0.0001)\n",
    "    auto_A_sqrt = np.sqrt(auto_A)\n",
    "    auto_B_sqrt = np.sqrt(auto_B)\n",
    "    denom = np.multiply(auto_A_sqrt, auto_B_sqrt).max() # (THIS WORKS.) (Basically uhm so the normalization amt should be the same throughout? I'm not v sure why this works...)\n",
    "\n",
    "    return np.divide(Z, denom).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cd353a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising\n",
    "\n",
    "ncc_score = ncc_fft_numba(test_img, test_img2)\n",
    "ncc_score = ncc_rfft_numba(test_img, test_img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a1c9dea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocket-fft ncc fft runtime: 0.0003742503084940836\n",
      "ncc fft runtime: 0.0008130941656418145\n",
      "cv2 ncc runtime: 0.002791567355277948\n",
      "ncc rfft rocket runtime: 0.003096092461259104\n"
     ]
    }
   ],
   "source": [
    "# Rocket-fft consistently faster! Yippee.\n",
    "import time\n",
    "\n",
    "runs = 1000\n",
    "ttime = 0\n",
    "\n",
    "for i in range(runs):\n",
    "    start_time = time.perf_counter()\n",
    "    ncc_score = ncc_fft_numba(test_img, test_img2)\n",
    "    end_time = time.perf_counter()\n",
    "    ttime += end_time - start_time\n",
    "\n",
    "print(f\"rocket-fft ncc fft runtime: {ttime / runs}\")\n",
    "\n",
    "for i in range(runs):\n",
    "    start_time = time.perf_counter()\n",
    "    ncc_score = ncc_fft(test_img, test_img2)\n",
    "    end_time = time.perf_counter()\n",
    "    ttime += end_time - start_time\n",
    "\n",
    "print(f\"ncc fft runtime: {ttime / runs}\")\n",
    "\n",
    "for i in range(runs):\n",
    "    start_time = time.perf_counter()\n",
    "    ncc_score = ncc(test_img, test_img2)\n",
    "    end_time = time.perf_counter()\n",
    "    ttime += end_time - start_time\n",
    "\n",
    "print(f\"cv2 ncc runtime: {ttime / runs}\")\n",
    "\n",
    "for i in range(runs):\n",
    "    start_time = time.perf_counter()\n",
    "    ncc_score = ncc_rfft_numba(test_img, test_img2)\n",
    "    end_time = time.perf_counter()\n",
    "    ttime += end_time - start_time\n",
    "\n",
    "print(f\"ncc rfft rocket runtime: {ttime / runs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d3ca163",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda, vectorize, float64\n",
    "\n",
    "\n",
    "# @cuda.jit()\n",
    "# def linear_ncc_search(testSample, unseen_image, k, arr):\n",
    "#     i = cuda.grid(1)\n",
    "#     if (i < len(testSample)):\n",
    "#         arr[i] = ncc_fft_numba(testSample[i], unseen_image)\n",
    "\n",
    "@vectorize([float64(float64, float64)], cache=True)\n",
    "def f(x, y):\n",
    "    return ncc_fft_numba(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63a4c7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = get_data_MStar(32)\n",
    "\n",
    "sample_indices = random.sample(range(len(data)), 50)\n",
    "sampled_test_data = Subset(data, sample_indices)\n",
    "\n",
    "testSample = [item[0] for item in sampled_test_data]\n",
    "print(len(testSample))\n",
    "index1 = np.random.randint(len(data))\n",
    "#input1=input_dataset[index1][0].squeeze().to('cpu')\n",
    "unseen_image = data[index1][0]\n",
    "unseen_images = np.array([unseen_image for i in range(len(testSample))])\n",
    "\n",
    "\n",
    "k=7\n",
    "\n",
    "# x_host = np.ones(shape=(len(testSample)))\n",
    "# x_device = cuda.to_device(x_host)\n",
    "# threadsperblock = 256\n",
    "# blockspergrid = (x_device.size + (threadsperblock - 1)) // threadsperblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9c183d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m start_time = time.perf_counter()\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# arr = [-1 for i in range(len(testSample))]\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# linear_ncc_search[blockspergrid, threadsperblock](testSample, unseen_image, k, arr)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m unseen_img_arr = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestSample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munseen_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m#unseen_img_arr = np.array(x_device)\u001b[39;00m\n\u001b[32m      6\u001b[39m imgProd_max_index = np.argpartition(unseen_img_arr, -(k+\u001b[32m1\u001b[39m))[-(k+\u001b[32m1\u001b[39m):]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/miniconda/envs/cupy-env/lib/python3.12/site-packages/numba/np/ufunc/dufunc.py:288\u001b[39m, in \u001b[36mDUFunc.__call__\u001b[39m\u001b[34m(self, *args, **kws)\u001b[39m\n\u001b[32m    286\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkws\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.perf_counter()\n",
    "# arr = [-1 for i in range(len(testSample))]\n",
    "# linear_ncc_search[blockspergrid, threadsperblock](testSample, unseen_image, k, arr)\n",
    "unseen_img_arr = f(testSample, unseen_images)\n",
    "#unseen_img_arr = np.array(x_device)\n",
    "imgProd_max_index = np.argpartition(unseen_img_arr, -(k+1))[-(k+1):]\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "print(f\"time: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "df8ed1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import prange\n",
    "\n",
    "@nb.njit(parallel=True)\n",
    "def linear_ncc_psearch(testSample, unseen_image, arr):\n",
    "    for i in prange(len(testSample)):\n",
    "        arr[i] = ncc_fft_numba(testSample[i], unseen_image)\n",
    "\n",
    "    return arr\n",
    "\n",
    "@nb.njit()\n",
    "def linear_ncc_search(testSample, unseen_image, arr):\n",
    "    for i in range(len(testSample)):\n",
    "        arr[i] = ncc_fft_numba(testSample[i], unseen_image)\n",
    "\n",
    "    return arr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c114f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<CUDA device 0 'b'NVIDIA RTX 6000 Ada Generation''>\n",
      "47089123328\n",
      "47089123328\n",
      "<numba.cuda.cudadrv.devicearray.DeviceNDArray object at 0x7f25422b3c80>\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "\n",
    "# Measures free memory bef and aft allocation to device.\n",
    "print(cuda.select_device(0))\n",
    "print(cuda.current_context().get_memory_info()[0])\n",
    "arr = np.zeros(10**9, dtype = 'float32')\n",
    "d_ary = cuda.to_device(arr)\n",
    "print(cuda.current_context().get_memory_info()[0])\n",
    "print(d_ary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29354ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = 1\n",
    "ttime = 0\n",
    "image_size = 100\n",
    "sample_size = 9000\n",
    "\n",
    "# data = get_data_MStar(image_size)\n",
    "\n",
    "# sample_indices = random.sample(range(len(data)), sample_size)\n",
    "# sampled_test_data = Subset(data, sample_indices)\n",
    "\n",
    "# testSample = [item[0] for item in sampled_test_data]\n",
    "# index1 = np.random.randint(len(data))\n",
    "# #input1=input_dataset[index1][0].squeeze().to('cpu')\n",
    "# unseen_image = data[index1][0]\n",
    "\n",
    "data = get_data_MStar(image_size)\n",
    "sample_indices = random.sample(range(len(data)), sample_size)\n",
    "sampled_test_data = Subset(data, sample_indices)\n",
    "\n",
    "testSample = [item[0] for item in sampled_test_data]\n",
    "index1 = np.random.randint(len(data))\n",
    "unseen_image = data[index1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974913a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m testSample = \u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msampled_test_data\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      2\u001b[39m testSample = np.array(testSample)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/miniconda/envs/cupy-env/lib/python3.12/site-packages/torch/utils/data/dataset.py:412\u001b[39m, in \u001b[36mSubset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    411\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset[[\u001b[38;5;28mself\u001b[39m.indices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[32m--> \u001b[39m\u001b[32m412\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mCustomDatasetMStar.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[32m     59\u001b[39m     data_path = \u001b[38;5;28mself\u001b[39m.data[index]\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     image = \u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m     image = transforms.functional.to_grayscale(image)\n\u001b[32m     62\u001b[39m     class_id = \u001b[38;5;28mself\u001b[39m.class_map[data_path[\u001b[32m1\u001b[39m]]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/miniconda/envs/cupy-env/lib/python3.12/site-packages/PIL/Image.py:3505\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(fp, mode, formats)\u001b[39m\n\u001b[32m   3502\u001b[39m     filename = os.fspath(fp)\n\u001b[32m   3504\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[32m-> \u001b[39m\u001b[32m3505\u001b[39m     fp = \u001b[43mbuiltins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3506\u001b[39m     exclusive_fp = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   3507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "testSample = [item[0] for item in sampled_test_data]\n",
    "testSample = np.array(testSample)\n",
    "print(testSample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca8ebf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<CUDA device 0 'b'NVIDIA RTX 6000 Ada Generation''>\n"
     ]
    }
   ],
   "source": [
    "# Testing amt of memory req for alloc of testSample array, MStar 9000 images, 100x100\n",
    "print(cuda.select_device(0))\n",
    "# before = cuda.current_context().get_memory_info()[0]\n",
    "# print(before)\n",
    "# d_ary = cuda.to_device(testSample)\n",
    "# after = cuda.current_context().get_memory_info()[0]\n",
    "# print(after)\n",
    "# print(int(before - after) / 10**9)\n",
    "# print(d_ary)\n",
    "\n",
    "# 0.36 GB for 9000 x 100 x 100 array w float values inside... 10k x say \n",
    "# I should find out if its float32 or float64... if its 32 itll be 10k x 4 so 40k x 9k = 360k oh! It's exactly right.\n",
    "# Ok so we are using float32, the mem required for the initial array passed in is sample_size x (image_size^2) x 4. so for 100k it wld be 100k x 200^2 x 4. aka 16 GB. Which we do have.\n",
    "# If we wanna do fft... then ok we have 1 unseen image thats 4(N^2)B. Seems to be complex64, so lets take it as that.\n",
    "# So that would mean 16B per complex num... so size(A) = 16(N^2) = size(B). Suppose its all that.... then 5*8*(N^2) per image... so it should be in addition???? thats alot man. confusion.\n",
    "# Ok so taking complex64, supposing it deletes aft no more reference, it can decrease to like (8*2 + 4)N^2 so w 100k, 200x200 that becomes 80GB which works out. \n",
    "# OHHH wait. so A, B are complex64, Z is float 32. ye ok. Hm. Maybs I can dec the memory required by not keeping a reference to A/B? Tho will be slower.\n",
    "# Waaaaaaait parallel=True parallelises on CPU TT SOOO im not even using GPU ???\n",
    "\n",
    "\n",
    "# def ncc_fft(mainImg, tempImg):\n",
    "#     before = cuda.current_context().get_memory_info()[0]\n",
    "#     print(before)\n",
    "#     A = scipy.fft.fft2(mainImg)\n",
    "#     B = scipy.fft.fft2(tempImg)\n",
    "#     print(type(A[0][0]))\n",
    "\n",
    "#     Z = np.ascontiguousarray(scipy.fft.ifft2(np.conj(A) * B).real)\n",
    "#     print(type(Z[0][0]))\n",
    "#     # IT'S OK UP TO THIS POINT!!\n",
    "#     AC = cuda.to_device(A)\n",
    "#     BC = cuda.to_device(B)\n",
    "#     ZC = cuda.to_device(Z)\n",
    "#     after = cuda.current_context().get_memory_info()[0]\n",
    "#     print(after)\n",
    "#     print(f\"Memory immediately aft alloc A, B, C: {int(before - after) / 10**9}\")\n",
    "#     print(AC)\n",
    "#     auto_A = np.ascontiguousarray(scipy.fft.ifft2(np.conj(A) * A).real)\n",
    "#     print(BC)\n",
    "#     auto_B = np.ascontiguousarray(scipy.fft.ifft2(np.conj(B) * B).real)\n",
    "#     auto_AC = cuda.to_device(auto_A)\n",
    "#     auto_BC = cuda.to_device(auto_B)\n",
    "#     after = cuda.current_context().get_memory_info()[0]\n",
    "#     print(after)\n",
    "#     print(f\"Memory immediately aft alloc auto_A, auto_ B: {int(before - after) / 10**9}\")\n",
    "#     auto_A = np.maximum(auto_A, 0.0001)\n",
    "#     auto_B = np.maximum(auto_B, 0.0001)\n",
    "#     auto_A_sqrt = np.sqrt(auto_A)\n",
    "#     print(auto_AC)\n",
    "#     auto_B_sqrt = np.sqrt(auto_B)\n",
    "#     print(auto_BC)\n",
    "#     after = cuda.current_context().get_memory_info()[0]\n",
    "#     print(after)\n",
    "#     print(f\"Memory immediately aft calc auto_AB sqrt: {int(before - after) / 10**9}\")\n",
    "#     denom = np.multiply(auto_A_sqrt, auto_B_sqrt).max()\n",
    "\n",
    "#     after = cuda.current_context().get_memory_info()[0]\n",
    "#     print(after)\n",
    "#     print(f\"Memory END: {int(before - after) / 10**9}\")\n",
    "#     print(ZC)\n",
    "#     return np.divide(Z, denom).max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bff1af92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47089123328\n",
      "<class 'numpy.complex64'>\n",
      "<class 'numpy.float32'>\n",
      "47089123328\n",
      "Memory immediately aft alloc A, B, C: 0.0\n",
      "<numba.cuda.cudadrv.devicearray.DeviceNDArray object at 0x7f250b205400>\n",
      "<numba.cuda.cudadrv.devicearray.DeviceNDArray object at 0x7f250b3af800>\n",
      "47089123328\n",
      "Memory immediately aft alloc auto_A, auto_ B: 0.0\n",
      "<numba.cuda.cudadrv.devicearray.DeviceNDArray object at 0x7f250b1f9310>\n",
      "<numba.cuda.cudadrv.devicearray.DeviceNDArray object at 0x7f250b2750d0>\n",
      "47089123328\n",
      "Memory immediately aft calc auto_AB sqrt: 0.0\n",
      "47089123328\n",
      "Memory END: 0.0\n",
      "<numba.cuda.cudadrv.devicearray.DeviceNDArray object at 0x7f250b3ad2b0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float32(0.7826467)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncc_fft(testSample[0], testSample[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c672d12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unseen image class: 3\n"
     ]
    },
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1mFailed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1m\u001b[1m\u001b[1mNo implementation of function Function(<uarray multimethod 'fft2'>) found for signature:\n \n >>> fft2(Tuple(array(float32, 2d, C), int64))\n \nThere are 2 candidate implementations:\n\u001b[1m  - Of which 2 did not match due to:\n  Overload in function '_scipy_c2d': File: rocket_fft/overloads.py: Line 533.\n    With argument(s): '(Tuple(array(float32, 2d, C), int64))':\u001b[0m\n\u001b[1m   Rejected as the implementation raised a specific error:\n     TypingError: \u001b[1mThe 1st argument 'x' must be an array.\u001b[0m\u001b[0m\n  raised from /root/miniconda/envs/cupy-env/lib/python3.12/site-packages/rocket_fft/typutils.py:82\n\u001b[0m\n\u001b[0m\u001b[1mDuring: resolving callee type: Function(<uarray multimethod 'fft2'>)\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of call at /tmp/ipykernel_1312117/4085139670.py (6)\n\u001b[0m\n\u001b[1m\nFile \"../../../tmp/ipykernel_1312117/4085139670.py\", line 6:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\n\u001b[0m\u001b[1mDuring: Pass nopython_type_inference\u001b[0m\n\u001b[0m\u001b[1mDuring: resolving callee type: type(CPUDispatcher(<function ncc_fft_numba at 0x7f2548b34ea0>))\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of call at /tmp/ipykernel_1312117/2821647146.py (6)\n\u001b[0m\n\u001b[0m\u001b[1mDuring: resolving callee type: type(CPUDispatcher(<function ncc_fft_numba at 0x7f2548b34ea0>))\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of call at /tmp/ipykernel_1312117/2821647146.py (6)\n\u001b[0m\n\u001b[1m\nFile \"../../../tmp/ipykernel_1312117/2821647146.py\", line 6:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\n\u001b[0m\u001b[1mDuring: Pass nopython_type_inference\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypingError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# print()\u001b[39;00m\n\u001b[32m     23\u001b[39m arr = np.ones(\u001b[38;5;28mlen\u001b[39m(testSample))\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m unseen_img_arr = \u001b[43mlinear_ncc_psearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestSample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munseen_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m imgProd_max_index = np.argpartition(unseen_img_arr, -(k+\u001b[32m1\u001b[39m))[-(k+\u001b[32m1\u001b[39m):]\n\u001b[32m     27\u001b[39m other = linear_ncc_search(testSample, unseen_image, arr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/miniconda/envs/cupy-env/lib/python3.12/site-packages/numba/core/dispatcher.py:424\u001b[39m, in \u001b[36m_DispatcherBase._compile_for_args\u001b[39m\u001b[34m(self, *args, **kws)\u001b[39m\n\u001b[32m    420\u001b[39m         msg = (\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e).rstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mThis error may have been caused \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    421\u001b[39m                \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mby the following argument(s):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00margs_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    422\u001b[39m         e.patch_message(msg)\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m     \u001b[43merror_rewrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtyping\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m errors.UnsupportedError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    426\u001b[39m     \u001b[38;5;66;03m# Something unsupported is present in the user code, add help info\u001b[39;00m\n\u001b[32m    427\u001b[39m     error_rewrite(e, \u001b[33m'\u001b[39m\u001b[33munsupported_error\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/root/miniconda/envs/cupy-env/lib/python3.12/site-packages/numba/core/dispatcher.py:365\u001b[39m, in \u001b[36m_DispatcherBase._compile_for_args.<locals>.error_rewrite\u001b[39m\u001b[34m(e, issue_type)\u001b[39m\n\u001b[32m    363\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mTypingError\u001b[39m: Failed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1m\u001b[1m\u001b[1m\u001b[1mFailed in nopython mode pipeline (step: nopython frontend)\n\u001b[1m\u001b[1m\u001b[1m\u001b[1mNo implementation of function Function(<uarray multimethod 'fft2'>) found for signature:\n \n >>> fft2(Tuple(array(float32, 2d, C), int64))\n \nThere are 2 candidate implementations:\n\u001b[1m  - Of which 2 did not match due to:\n  Overload in function '_scipy_c2d': File: rocket_fft/overloads.py: Line 533.\n    With argument(s): '(Tuple(array(float32, 2d, C), int64))':\u001b[0m\n\u001b[1m   Rejected as the implementation raised a specific error:\n     TypingError: \u001b[1mThe 1st argument 'x' must be an array.\u001b[0m\u001b[0m\n  raised from /root/miniconda/envs/cupy-env/lib/python3.12/site-packages/rocket_fft/typutils.py:82\n\u001b[0m\n\u001b[0m\u001b[1mDuring: resolving callee type: Function(<uarray multimethod 'fft2'>)\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of call at /tmp/ipykernel_1312117/4085139670.py (6)\n\u001b[0m\n\u001b[1m\nFile \"../../../tmp/ipykernel_1312117/4085139670.py\", line 6:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\n\u001b[0m\u001b[1mDuring: Pass nopython_type_inference\u001b[0m\n\u001b[0m\u001b[1mDuring: resolving callee type: type(CPUDispatcher(<function ncc_fft_numba at 0x7f2548b34ea0>))\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of call at /tmp/ipykernel_1312117/2821647146.py (6)\n\u001b[0m\n\u001b[0m\u001b[1mDuring: resolving callee type: type(CPUDispatcher(<function ncc_fft_numba at 0x7f2548b34ea0>))\u001b[0m\n\u001b[0m\u001b[1mDuring: typing of call at /tmp/ipykernel_1312117/2821647146.py (6)\n\u001b[0m\n\u001b[1m\nFile \"../../../tmp/ipykernel_1312117/2821647146.py\", line 6:\u001b[0m\n\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n\n\u001b[0m\u001b[1mDuring: Pass nopython_type_inference\u001b[0m"
     ]
    }
   ],
   "source": [
    "k = 7\n",
    "runs = 100\n",
    "ttime = 0\n",
    "image_size = 16\n",
    "sample_size = 20000\n",
    "\n",
    "# data = get_data_SARDet_100k(image_size)\n",
    "\n",
    "# sample_indices = random.sample(range(len(data)), sample_size)\n",
    "# sampled_test_data = Subset(data, sample_indices)\n",
    "\n",
    "# testSample = [item[0] for item in sampled_test_data]\n",
    "# classes = [item[1] for item in sampled_test_data]\n",
    "# testSampleIndexed = [(item, i) for item in testSample]\n",
    "# index1 = np.random.randint(len(data))\n",
    "# # #input1=input_dataset[index1][0].squeeze().to('cpu')\n",
    "# unseen_image = data[index1][0]\n",
    "# unseen_image_class = data[index1][1]\n",
    "\n",
    "print(f\"Unseen image class: {unseen_image_class}\")\n",
    "# print()\n",
    "\n",
    "arr = np.ones(len(testSample))\n",
    "unseen_img_arr = linear_ncc_psearch(testSample, unseen_image, arr)\n",
    "imgProd_max_index = np.argpartition(unseen_img_arr, -(k+1))[-(k+1):]\n",
    "\n",
    "other = linear_ncc_search(testSample, unseen_image, arr)\n",
    "other_index = np.argpartition(other, -(k+1))[-(k+1):]\n",
    "# print()\n",
    "for i in range(len(imgProd_max_index)):\n",
    "    print(classes[imgProd_max_index[i]])\n",
    "\n",
    "for i in range(len(other_index)):\n",
    "    print(classes[other_index[i]])\n",
    "\n",
    "# data = get_data(image_size)\n",
    "# sample_indices = random.sample(range(len(data)), sample_size)\n",
    "# sampled_test_data = Subset(data, sample_indices)\n",
    "\n",
    "# testSample = [item for item in sampled_test_data]\n",
    "# index1 = np.random.randint(len(data))\n",
    "# unseen_image = data[index1]\n",
    "\n",
    "# for i in range(runs):\n",
    "#     start_time = time.perf_counter()\n",
    "#     arr = np.ones(len(testSample))\n",
    "#     unseen_img_arr = linear_ncc_psearch(testSample, unseen_image, arr)\n",
    "#     imgProd_max_index = np.argpartition(unseen_img_arr, -(k+1))[-(k+1):]\n",
    "#     end_time = time.perf_counter()\n",
    "#     ttime += end_time - start_time\n",
    "\n",
    "# print(f\"time taken for parallelised linear ncc search with rocket fft over {runs} runs for image size {image_size} and sample size {sample_size} : {ttime / runs}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f758028",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of mtree.mtree failed: Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/cupy-env/lib/python3.12/site-packages/IPython/extensions/autoreload.py\", line 283, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/root/miniconda/envs/cupy-env/lib/python3.12/site-packages/IPython/extensions/autoreload.py\", line 483, in superreload\n",
      "    module = reload(module)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda/envs/cupy-env/lib/python3.12/importlib/__init__.py\", line 131, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 866, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "  File \"/home/jovyan/mtree/mtree.py\", line 95, in <module>\n",
      "    from mst_split import Graph\n",
      "ModuleNotFoundError: No module named 'mst_split'\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "runs = 1\n",
    "ttime = 0\n",
    "image_size = 16\n",
    "sample_size = 100000\n",
    "# data = get_data_MStar(image_size)\n",
    "\n",
    "# sample_indices = random.sample(range(len(data)), sample_size)\n",
    "# sampled_test_data = Subset(data, sample_indices)\n",
    "\n",
    "# testSample = [item[0] for item in sampled_test_data]\n",
    "# index1 = np.random.randint(len(data))\n",
    "# unseen_image = data[index1][0]\n",
    "\n",
    "# data = get_data(image_size)\n",
    "# sample_indices = random.sample(range(len(data)), sample_size)\n",
    "# sampled_test_data = Subset(data, sample_indices)\n",
    "\n",
    "# testSample = [item for item in sampled_test_data]\n",
    "# index1 = np.random.randint(len(data))\n",
    "# unseen_image = data[index1]\n",
    "\n",
    "for i in range(runs):\n",
    "    start_time = time.perf_counter()\n",
    "    arr = np.ones(len(testSample))\n",
    "    unseen_img_arr = linear_ncc_search(testSample, unseen_image, arr)\n",
    "    imgProd_max_index = np.argpartition(unseen_img_arr, -(k+1))[-(k+1):]\n",
    "    end_time = time.perf_counter()\n",
    "    ttime += end_time - start_time\n",
    "\n",
    "print(f\"time taken for linear ncc search with rocket fft over {runs} runs for image size {image_size} and sample size {sample_size} : {ttime / runs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "1b1cda74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for mtree init with rocket fft over 1 runs for image size 16 and sample size 100 : 0.15543346898630261\n",
      "time taken for mtree with rocket fft over 10 runs for image size 16 and sample size 100 : 0.005399227695306763\n"
     ]
    }
   ],
   "source": [
    "runs = 10\n",
    "ttime = 0\n",
    "image_size = 16\n",
    "sample_size = 100\n",
    "data = get_data_SARDet_100k(image_size)\n",
    "\n",
    "sample_indices = random.sample(range(len(data)), sample_size)\n",
    "sampled_test_data = Subset(data, sample_indices)\n",
    "\n",
    "testSample = [item[0] for item in sampled_test_data]\n",
    "index1 = np.random.randint(len(data))\n",
    "#input1=input_dataset[index1][0].squeeze().to('cpu')\n",
    "unseen_image = data[index1][0]\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "tree = getMTreeFFT(testSample, 12)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "print(f\"time taken for mtree init with rocket fft over {1} runs for image size {image_size} and sample size {sample_size} : {end_time - start_time}\")\n",
    "\n",
    "for i in range(runs):\n",
    "    index1 = np.random.randint(len(data))\n",
    "    #input1=input_dataset[index1][0].squeeze().to('cpu')\n",
    "    unseen_image = data[index1][0]\n",
    "    start_time = time.perf_counter()\n",
    "    arr = np.ones(len(testSample))\n",
    "    img_arr = getKNearestNeighbours(tree, unseen_image, k)\n",
    "    end_time = time.perf_counter()\n",
    "    ttime += end_time - start_time\n",
    "\n",
    "print(f\"time taken for mtree with rocket fft over {runs} runs for image size {image_size} and sample size {sample_size} : {ttime / runs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "aeff9086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken for linear ncc search with rocket fft over 1 runs for image size 16 and sample size 100 : 0.27072279807180166\n"
     ]
    }
   ],
   "source": [
    "runs = 1\n",
    "ttime = 0\n",
    "image_size = 16\n",
    "sample_size = 100\n",
    "\n",
    "data = get_data_MStar(image_size)\n",
    "\n",
    "sample_indices = random.sample(range(len(data)), sample_size)\n",
    "sampled_test_data = Subset(data, sample_indices)\n",
    "\n",
    "testSample = [item[0] for item in sampled_test_data]\n",
    "index1 = np.random.randint(len(data))\n",
    "unseen_image = data[index1][0]\n",
    "\n",
    "# data = get_data(image_size)\n",
    "# sample_indices = random.sample(range(len(data)), sample_size)\n",
    "# sampled_test_data = Subset(data, sample_indices)\n",
    "\n",
    "# testSample = [item for item in sampled_test_data]\n",
    "# index1 = np.random.randint(len(data))\n",
    "# unseen_image = data[index1]\n",
    "\n",
    "for i in range(runs):\n",
    "    start_time = time.perf_counter()\n",
    "    arr = np.ones(len(testSample))\n",
    "    unseen_img_arr = linear_ncc_search(testSample, unseen_image, arr)\n",
    "    imgProd_max_index = np.argpartition(unseen_img_arr, -(k+1))[-(k+1):]\n",
    "    end_time = time.perf_counter()\n",
    "    ttime += end_time - start_time\n",
    "\n",
    "print(f\"time taken for linear ncc search with rocket fft over {runs} runs for image size {image_size} and sample size {sample_size} : {ttime / runs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94e4379",
   "metadata": {},
   "source": [
    "## Accuracy test sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c74a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n",
      "ncc parallel rocket fft: [np.int64(8), np.int64(2), np.int64(4)]\n",
      "mtree normal: [8, 2]\n",
      "DISTANCE TO IMG from index 8: 0.021291202588343574\n",
      "DISTANCE TO IMG W INDEX from index 8: 0.021291202588343574\n",
      "DISTANCE TO IMG TEST from index 0: 0.021291202588343574\n",
      "DISTANCE TO IMG from index 8: 0.021291202588343574\n",
      "DISTANCE TO IMG W INDEX from index 8: 0.021291202588343574\n",
      "DISTANCE TO IMG TEST from index 1: 0.0\n",
      "DISTANCE TO IMG from index 8: 0.021291202588343574\n",
      "DISTANCE TO IMG W INDEX from index 8: 0.021291202588343574\n",
      "DISTANCE TO IMG TEST from index 2: 0.04560509504304238\n",
      "DISTANCE TO IMG from index 2: 0.0\n",
      "DISTANCE TO IMG W INDEX from index 2: 0.0\n",
      "DISTANCE TO IMG TEST from index 0: 0.021291202588343574\n",
      "DISTANCE TO IMG from index 2: 0.0\n",
      "DISTANCE TO IMG W INDEX from index 2: 0.0\n",
      "DISTANCE TO IMG TEST from index 1: 0.0\n",
      "DISTANCE TO IMG from index 2: 0.0\n",
      "DISTANCE TO IMG W INDEX from index 2: 0.0\n",
      "DISTANCE TO IMG TEST from index 2: 0.04560509504304238\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "ncc parallel rocket fft: [np.int64(3), np.int64(0), np.int64(19)]\n",
      "mtree normal: [0, 3]\n",
      "DISTANCE TO IMG from index 0: 0.0\n",
      "DISTANCE TO IMG W INDEX from index 0: 0.0\n",
      "DISTANCE TO IMG TEST from index 0: 0.07030950270304367\n",
      "DISTANCE TO IMG from index 0: 0.0\n",
      "DISTANCE TO IMG W INDEX from index 0: 0.0\n",
      "DISTANCE TO IMG TEST from index 1: 0.0\n",
      "DISTANCE TO IMG from index 0: 0.0\n",
      "DISTANCE TO IMG W INDEX from index 0: 0.0\n",
      "DISTANCE TO IMG TEST from index 2: 0.08636705249865388\n",
      "DISTANCE TO IMG from index 3: 0.07030950270304367\n",
      "DISTANCE TO IMG W INDEX from index 3: 0.07030950270304367\n",
      "DISTANCE TO IMG TEST from index 0: 0.07030950270304367\n",
      "DISTANCE TO IMG from index 3: 0.07030950270304367\n",
      "DISTANCE TO IMG W INDEX from index 3: 0.07030950270304367\n",
      "DISTANCE TO IMG TEST from index 1: 0.0\n",
      "DISTANCE TO IMG from index 3: 0.07030950270304367\n",
      "DISTANCE TO IMG W INDEX from index 3: 0.07030950270304367\n",
      "DISTANCE TO IMG TEST from index 2: 0.08636705249865388\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "ncc parallel rocket fft: [np.int64(0), np.int64(1), np.int64(15)]\n",
      "mtree normal: [0, 1]\n",
      "DISTANCE TO IMG from index 0: 0.037231573559550896\n",
      "DISTANCE TO IMG W INDEX from index 0: 0.037231573559550896\n",
      "DISTANCE TO IMG TEST from index 0: 0.037231573559550896\n",
      "DISTANCE TO IMG from index 0: 0.037231573559550896\n",
      "DISTANCE TO IMG W INDEX from index 0: 0.037231573559550896\n",
      "DISTANCE TO IMG TEST from index 1: 0.0\n",
      "DISTANCE TO IMG from index 0: 0.037231573559550896\n",
      "DISTANCE TO IMG W INDEX from index 0: 0.037231573559550896\n",
      "DISTANCE TO IMG TEST from index 2: 0.04766642470117464\n",
      "DISTANCE TO IMG from index 1: 0.0\n",
      "DISTANCE TO IMG W INDEX from index 1: 0.0\n",
      "DISTANCE TO IMG TEST from index 0: 0.037231573559550896\n",
      "DISTANCE TO IMG from index 1: 0.0\n",
      "DISTANCE TO IMG W INDEX from index 1: 0.0\n",
      "DISTANCE TO IMG TEST from index 1: 0.0\n",
      "DISTANCE TO IMG from index 1: 0.0\n",
      "DISTANCE TO IMG W INDEX from index 1: 0.0\n",
      "DISTANCE TO IMG TEST from index 2: 0.04766642470117464\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Trying to add Entry(obj: (array([[-0.8039216 , -0.7882353 , -0.7176471 , -0.7882353 , -0.70980394,\n        -0.75686276, -0.75686276, -0.78039217, -0.73333335, -0.75686276,\n        -0.7254902 , -0.7254902 , -0.7490196 , -0.73333335, -0.73333335,\n        -0.7882353 ],\n       [-0.827451  , -0.8039216 , -0.7647059 , -0.79607844, -0.7882353 ,\n        -0.8039216 , -0.77254903, -0.75686276, -0.73333335, -0.7254902 ,\n        -0.7019608 , -0.70980394, -0.73333335, -0.7411765 , -0.7176471 ,\n        -0.7254902 ],\n       [-0.79607844, -0.7254902 , -0.7411765 , -0.78039217, -0.7647059 ,\n        -0.7647059 , -0.75686276, -0.8039216 , -0.75686276, -0.6862745 ,\n        -0.7019608 , -0.69411767, -0.69411767, -0.7176471 , -0.7490196 ,\n        -0.73333335],\n       [-0.78039217, -0.77254903, -0.7411765 , -0.75686276, -0.70980394,\n        -0.7254902 , -0.73333335, -0.8352941 , -0.7882353 , -0.7019608 ,\n        -0.70980394, -0.6862745 , -0.7176471 , -0.7411765 , -0.7411765 ,\n        -0.6784314 ],\n       [-0.7647059 , -0.75686276, -0.73333335, -0.7647059 , -0.70980394,\n        -0.69411767, -0.70980394, -0.827451  , -0.78039217, -0.7176471 ,\n        -0.6627451 , -0.6862745 , -0.78039217, -0.7647059 , -0.75686276,\n        -0.73333335],\n       [-0.7882353 , -0.77254903, -0.7490196 , -0.7647059 , -0.7019608 ,\n        -0.67058825, -0.70980394, -0.7411765 , -0.7411765 , -0.7176471 ,\n        -0.7176471 , -0.73333335, -0.77254903, -0.75686276, -0.7490196 ,\n        -0.77254903],\n       [-0.8039216 , -0.77254903, -0.7647059 , -0.7882353 , -0.7490196 ,\n        -0.7490196 , -0.70980394, -0.36470586, -0.46666664, -0.69411767,\n        -0.73333335, -0.7647059 , -0.78039217, -0.7254902 , -0.70980394,\n        -0.7490196 ],\n       [-0.79607844, -0.75686276, -0.7411765 , -0.7411765 , -0.73333335,\n        -0.7254902 , -0.58431375,  0.33333337, -0.00392157, -0.6862745 ,\n        -0.6862745 , -0.73333335, -0.77254903, -0.7490196 , -0.7490196 ,\n        -0.70980394],\n       [-0.7647059 , -0.77254903, -0.7490196 , -0.70980394, -0.73333335,\n        -0.69411767, -0.5137255 ,  0.41176474,  0.20784318, -0.56078434,\n        -0.7411765 , -0.73333335, -0.75686276, -0.7647059 , -0.73333335,\n        -0.7019608 ],\n       [-0.7176471 , -0.73333335, -0.75686276, -0.7411765 , -0.7490196 ,\n        -0.7411765 , -0.654902  , -0.44313723, -0.5137255 , -0.7019608 ,\n        -0.7647059 , -0.70980394, -0.7647059 , -0.78039217, -0.73333335,\n        -0.7411765 ],\n       [-0.7647059 , -0.7176471 , -0.75686276, -0.7647059 , -0.7490196 ,\n        -0.7490196 , -0.75686276, -0.7490196 , -0.7647059 , -0.7411765 ,\n        -0.77254903, -0.7176471 , -0.7647059 , -0.79607844, -0.7490196 ,\n        -0.7176471 ],\n       [-0.6862745 , -0.7019608 , -0.7490196 , -0.7411765 , -0.7647059 ,\n        -0.77254903, -0.75686276, -0.7411765 , -0.70980394, -0.7176471 ,\n        -0.78039217, -0.7490196 , -0.75686276, -0.7647059 , -0.7254902 ,\n        -0.73333335],\n       [-0.6313726 , -0.6784314 , -0.7176471 , -0.73333335, -0.7411765 ,\n        -0.8039216 , -0.7882353 , -0.75686276, -0.7411765 , -0.75686276,\n        -0.77254903, -0.77254903, -0.75686276, -0.73333335, -0.7411765 ,\n        -0.7647059 ],\n       [-0.7176471 , -0.7019608 , -0.7019608 , -0.73333335, -0.7176471 ,\n        -0.77254903, -0.7882353 , -0.75686276, -0.75686276, -0.79607844,\n        -0.75686276, -0.7490196 , -0.7254902 , -0.6627451 , -0.70980394,\n        -0.70980394],\n       [-0.73333335, -0.6862745 , -0.7019608 , -0.7254902 , -0.73333335,\n        -0.73333335, -0.7647059 , -0.77254903, -0.77254903, -0.7411765 ,\n        -0.7647059 , -0.7647059 , -0.7647059 , -0.7647059 , -0.70980394,\n        -0.7411765 ],\n       [-0.7019608 , -0.7254902 , -0.7647059 , -0.7411765 , -0.75686276,\n        -0.75686276, -0.7176471 , -0.75686276, -0.7019608 , -0.7176471 ,\n        -0.7647059 , -0.77254903, -0.7647059 , -0.7411765 , -0.7411765 ,\n        -0.77254903]], dtype=float32), 5), dist: 0.15312352188823314, radius: 0.13376823211691816, subtree: 'LeafNode()') into a full node",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 85\u001b[39m\n\u001b[32m     77\u001b[39m imgProd_max_index_fft = np.argpartition(unseen_img_arr_fft, -(k+\u001b[32m1\u001b[39m))[-(k+\u001b[32m1\u001b[39m):]\n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# tree = getMTreeFFTNumba(testSample, 12)\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# img_arr = getKNearestNeighbours(tree, unseen_image, k)\u001b[39;00m\n\u001b[32m     81\u001b[39m \n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# ind_arr = imgs_to_indices(img_arr, testSample)\u001b[39;00m\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# print(len(img_arr))\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m normal_tree = \u001b[43mgetMTree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestSampleIndexed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpromote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmtree\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMST_promotion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartition\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmtree\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMST_partition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdist_fft_numba_indexed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[38;5;66;03m# print(len(normal_tree))\u001b[39;00m\n\u001b[32m     87\u001b[39m img_arr_2 = getKNearestNeighbours(normal_tree, unseen_image_indexed, k=\u001b[32m3\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mgetMTree\u001b[39m\u001b[34m(data, k, promote, partition, d)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgetMTree\u001b[39m(data, k, promote=mtree.M_LB_DIST_confirmed, partition=mtree.generalized_hyperplane, d=metrics.distance):\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# k: desired number of nearest neighbours\u001b[39;00m\n\u001b[32m     40\u001b[39m     tree = MTree(d, max_node_size=k, promote=promote, partition=partition)\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[43mtree\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tree\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mtree/mtree.py:241\u001b[39m, in \u001b[36mMTree.add_all\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m    239\u001b[39m \u001b[38;5;66;03m#TODO: implement using the bulk-loading algorithm\u001b[39;00m\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mtree/mtree.py:232\u001b[39m, in \u001b[36mMTree.add\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj):\n\u001b[32m    229\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    230\u001b[39m \u001b[33;03m    Add an object into the M-tree\u001b[39;00m\n\u001b[32m    231\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mself\u001b[39m.size += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:16\u001b[39m, in \u001b[36madd\u001b[39m\u001b[34m(self, obj)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:16\u001b[39m, in \u001b[36madd\u001b[39m\u001b[34m(self, obj)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mtree/mtree.py:523\u001b[39m, in \u001b[36mLeafNode.add\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    521\u001b[39m     \u001b[38;5;28mself\u001b[39m.entries.add(new_entry)\n\u001b[32m    522\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m     \u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_root() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parent_node\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mtree/mtree.py:798\u001b[39m, in \u001b[36msplit\u001b[39m\u001b[34m(existing_node, entry, d)\u001b[39m\n\u001b[32m    793\u001b[39m     existing_node_entry.distance_to_parent = \\\n\u001b[32m    794\u001b[39m         d(existing_node_entry.obj, parent_node.parent_entry.obj)\n\u001b[32m    795\u001b[39m     new_node_entry.distance_to_parent = \\\n\u001b[32m    796\u001b[39m         d(new_node_entry.obj, parent_node.parent_entry.obj)\n\u001b[32m--> \u001b[39m\u001b[32m798\u001b[39m parent_node.remove_entry(old_existing_node_parent_entry)\n\u001b[32m    799\u001b[39m parent_node.add_entry(existing_node_entry)\n\u001b[32m    801\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m parent_node.is_full():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mtree/mtree.py:468\u001b[39m, in \u001b[36mAbstractNode.add_entry\u001b[39m\u001b[34m(self, entry)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Add an entry to this node.\u001b[39;00m\n\u001b[32m    464\u001b[39m \n\u001b[32m    465\u001b[39m \u001b[33;03mRaise ValueError if the node is full.\u001b[39;00m\n\u001b[32m    466\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_full():\n\u001b[32m--> \u001b[39m\u001b[32m468\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mTrying to add \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m into a full node\u001b[39m\u001b[33m'\u001b[39m % \u001b[38;5;28mstr\u001b[39m(entry))\n\u001b[32m    469\u001b[39m \u001b[38;5;28mself\u001b[39m.entries.add(entry)\n",
      "\u001b[31mValueError\u001b[39m: Trying to add Entry(obj: (array([[-0.8039216 , -0.7882353 , -0.7176471 , -0.7882353 , -0.70980394,\n        -0.75686276, -0.75686276, -0.78039217, -0.73333335, -0.75686276,\n        -0.7254902 , -0.7254902 , -0.7490196 , -0.73333335, -0.73333335,\n        -0.7882353 ],\n       [-0.827451  , -0.8039216 , -0.7647059 , -0.79607844, -0.7882353 ,\n        -0.8039216 , -0.77254903, -0.75686276, -0.73333335, -0.7254902 ,\n        -0.7019608 , -0.70980394, -0.73333335, -0.7411765 , -0.7176471 ,\n        -0.7254902 ],\n       [-0.79607844, -0.7254902 , -0.7411765 , -0.78039217, -0.7647059 ,\n        -0.7647059 , -0.75686276, -0.8039216 , -0.75686276, -0.6862745 ,\n        -0.7019608 , -0.69411767, -0.69411767, -0.7176471 , -0.7490196 ,\n        -0.73333335],\n       [-0.78039217, -0.77254903, -0.7411765 , -0.75686276, -0.70980394,\n        -0.7254902 , -0.73333335, -0.8352941 , -0.7882353 , -0.7019608 ,\n        -0.70980394, -0.6862745 , -0.7176471 , -0.7411765 , -0.7411765 ,\n        -0.6784314 ],\n       [-0.7647059 , -0.75686276, -0.73333335, -0.7647059 , -0.70980394,\n        -0.69411767, -0.70980394, -0.827451  , -0.78039217, -0.7176471 ,\n        -0.6627451 , -0.6862745 , -0.78039217, -0.7647059 , -0.75686276,\n        -0.73333335],\n       [-0.7882353 , -0.77254903, -0.7490196 , -0.7647059 , -0.7019608 ,\n        -0.67058825, -0.70980394, -0.7411765 , -0.7411765 , -0.7176471 ,\n        -0.7176471 , -0.73333335, -0.77254903, -0.75686276, -0.7490196 ,\n        -0.77254903],\n       [-0.8039216 , -0.77254903, -0.7647059 , -0.7882353 , -0.7490196 ,\n        -0.7490196 , -0.70980394, -0.36470586, -0.46666664, -0.69411767,\n        -0.73333335, -0.7647059 , -0.78039217, -0.7254902 , -0.70980394,\n        -0.7490196 ],\n       [-0.79607844, -0.75686276, -0.7411765 , -0.7411765 , -0.73333335,\n        -0.7254902 , -0.58431375,  0.33333337, -0.00392157, -0.6862745 ,\n        -0.6862745 , -0.73333335, -0.77254903, -0.7490196 , -0.7490196 ,\n        -0.70980394],\n       [-0.7647059 , -0.77254903, -0.7490196 , -0.70980394, -0.73333335,\n        -0.69411767, -0.5137255 ,  0.41176474,  0.20784318, -0.56078434,\n        -0.7411765 , -0.73333335, -0.75686276, -0.7647059 , -0.73333335,\n        -0.7019608 ],\n       [-0.7176471 , -0.73333335, -0.75686276, -0.7411765 , -0.7490196 ,\n        -0.7411765 , -0.654902  , -0.44313723, -0.5137255 , -0.7019608 ,\n        -0.7647059 , -0.70980394, -0.7647059 , -0.78039217, -0.73333335,\n        -0.7411765 ],\n       [-0.7647059 , -0.7176471 , -0.75686276, -0.7647059 , -0.7490196 ,\n        -0.7490196 , -0.75686276, -0.7490196 , -0.7647059 , -0.7411765 ,\n        -0.77254903, -0.7176471 , -0.7647059 , -0.79607844, -0.7490196 ,\n        -0.7176471 ],\n       [-0.6862745 , -0.7019608 , -0.7490196 , -0.7411765 , -0.7647059 ,\n        -0.77254903, -0.75686276, -0.7411765 , -0.70980394, -0.7176471 ,\n        -0.78039217, -0.7490196 , -0.75686276, -0.7647059 , -0.7254902 ,\n        -0.73333335],\n       [-0.6313726 , -0.6784314 , -0.7176471 , -0.73333335, -0.7411765 ,\n        -0.8039216 , -0.7882353 , -0.75686276, -0.7411765 , -0.75686276,\n        -0.77254903, -0.77254903, -0.75686276, -0.73333335, -0.7411765 ,\n        -0.7647059 ],\n       [-0.7176471 , -0.7019608 , -0.7019608 , -0.73333335, -0.7176471 ,\n        -0.77254903, -0.7882353 , -0.75686276, -0.75686276, -0.79607844,\n        -0.75686276, -0.7490196 , -0.7254902 , -0.6627451 , -0.70980394,\n        -0.70980394],\n       [-0.73333335, -0.6862745 , -0.7019608 , -0.7254902 , -0.73333335,\n        -0.73333335, -0.7647059 , -0.77254903, -0.77254903, -0.7411765 ,\n        -0.7647059 , -0.7647059 , -0.7647059 , -0.7647059 , -0.70980394,\n        -0.7411765 ],\n       [-0.7019608 , -0.7254902 , -0.7647059 , -0.7411765 , -0.75686276,\n        -0.75686276, -0.7176471 , -0.75686276, -0.7019608 , -0.7176471 ,\n        -0.7647059 , -0.77254903, -0.7647059 , -0.7411765 , -0.7411765 ,\n        -0.77254903]], dtype=float32), 5), dist: 0.15312352188823314, radius: 0.13376823211691816, subtree: 'LeafNode()') into a full node"
     ]
    }
   ],
   "source": [
    "# FIX THIS TMR TTTTT \n",
    "# problem occurs when distances are all 1 for every item in sample_Size.\n",
    "k=3\n",
    "runs = 100\n",
    "ttime = 0\n",
    "image_size = 16\n",
    "sample_size = 100000\n",
    "\n",
    "def imgs_to_indices(img_arr, testSample):\n",
    "    added = False\n",
    "    ind_arr = []\n",
    "    for img in img_arr:\n",
    "        added = False\n",
    "        for i in range(len(testSample)):\n",
    "            #print(metrics.distance(img, testSample[i]))\n",
    "            # 1e-7 for fft\n",
    "            if (metrics.distance(img, testSample[i]) < 1e-7):\n",
    "                ind_arr.append(i)\n",
    "                added = True\n",
    "                break\n",
    "        if (not added):\n",
    "            print(\"NOT ADDED\")\n",
    "            print(f\"ncc: {ncc(img,img)}\")\n",
    "            print(f\"img prod ncc: {ImageProducts.ncc(img, img)}\")\n",
    "            print(f\"ncc fft: {ncc_fft_numba(img, img)}\")\n",
    "            print(metrics.distance(img, img))\n",
    "            for j in range(len(testSample)):\n",
    "                print(metrics.distance(img, testSample[j]))\n",
    "                print(f\"ncc against test samples: {ncc(img,testSample[j])}\")\n",
    "\n",
    "    return ind_arr\n",
    "\n",
    "data = get_data_SARDet_100k(image_size)\n",
    "\n",
    "\n",
    "for i in range(runs):\n",
    "    sample_indices = random.sample(range(len(data)), sample_size)\n",
    "    sampled_test_data = Subset(data, sample_indices)\n",
    "\n",
    "    testSample = [item[0] for item in sampled_test_data]\n",
    "    testSampleIndexed = []\n",
    "    for i in range(len(testSample)):\n",
    "        testSampleIndexed.append((testSample[i], i))\n",
    "    index1 = np.random.choice(sample_indices)\n",
    "    # index1 = np.random.randint(len(testSample))\n",
    "    # print(f\"UNSEEN IMAGE INDEX: {index1}\")\n",
    "    #index1 = np.random.randint(len(data))\n",
    "    unseen_image = data[index1][0]\n",
    "    # unseen_image = testSample[index1]\n",
    "    unseen_image_indexed = [unseen_image, index1]\n",
    "    # for i in range(len(testSample)):\n",
    "    #     print(f\"DISTANCE FROM TEST SAMPLE {i} to image: {metrics.dist_fft_numba(testSample[i], unseen_image)}\")\n",
    "    #     print(f\"NCC SCORES FROM TEST SAMPLE {i} to image: {ncc_fft_numba(testSample[i], unseen_image)}\")\n",
    "\n",
    "    # unseen_img_arr = linear_ncc_search(testSample, unseen_image, arr)\n",
    "    # imgProd_max_index = np.argpartition(unseen_img_arr, -(k+1))[-(k+1):]\n",
    "    arr = np.ones(len(testSample))\n",
    "    unseen_img_parr = linear_ncc_psearch(testSample, unseen_image, arr)\n",
    "    imgProd_max_pindex = np.argpartition(unseen_img_parr, -(k+1))[-(k+1):]\n",
    "\n",
    "    # arr = []\n",
    "    # for j in range(len(testSample)):\n",
    "    #     result = ncc(testSample[j], unseen_image)\n",
    "    #     arr.append(result)\n",
    "\n",
    "    # unseen_img_arr_normal = np.array(arr)\n",
    "    # #print(unseen_img_arr)\n",
    "    # imgProd_max_index_normal = np.argpartition(unseen_img_arr_normal, -(k+1))[-(k+1):]\n",
    "\n",
    "    # arr = []\n",
    "    # for j in range(len(testSample)):\n",
    "    #     result = ncc_fft(testSample[j], unseen_image)\n",
    "    #     arr.append(result)\n",
    "\n",
    "    unseen_img_arr_fft = np.array(arr)\n",
    "    #print(unseen_img_arr)\n",
    "    imgProd_max_index_fft = np.argpartition(unseen_img_arr_fft, -(k+1))[-(k+1):]\n",
    "\n",
    "    # tree = getMTreeFFTNumba(testSample, 12)\n",
    "    # img_arr = getKNearestNeighbours(tree, unseen_image, k)\n",
    "\n",
    "    # ind_arr = imgs_to_indices(img_arr, testSample)\n",
    "    # print(len(img_arr))\n",
    "\n",
    "    normal_tree = getMTree(testSampleIndexed, 3, promote=mtree.MST_promotion, partition=mtree.MST_partition, d=metrics.dist_fft_numba_indexed)\n",
    "    # print(len(normal_tree))\n",
    "    img_arr_2 = getKNearestNeighbours(normal_tree, unseen_image_indexed, k=3)\n",
    "    print(len(img_arr_2))\n",
    "    img_arr_2 = [item[1] for item in img_arr_2]\n",
    "\n",
    "    #print(img_arr_2)\n",
    "    # print(len(img_arr_2))    \n",
    "    # ind_arr_2 = imgs_to_indices(img_arr_2, testSample)\n",
    "\n",
    "    # mtree_fft = getMTreeFFT(testSample, 12)\n",
    "    # img_arr_3 = getKNearestNeighbours(tree, unseen_image, k)\n",
    "    # ind_arr_3 = imgs_to_indices(img_arr_3, testSample)\n",
    "\n",
    "    # tree_mst = getMTreeFFTNumba(testSample, 12, promote=mtree.MST_promotion, partition=mtree.MST_partition)\n",
    "    # img_arr = getKNearestNeighbours(tree_mst, unseen_image, k)\n",
    "    # ind_arr_3 = imgs_to_indices(img_arr, testSample)\n",
    "\n",
    "    # tree_mst_normal = getMTree(testSample, 12, promote=mtree.MST_promotion, partition=mtree.MST_partition)\n",
    "    # img_arr = getKNearestNeighbours(tree_mst_normal, unseen_image, k)\n",
    "    # ind_arr_4 = imgs_to_indices(img_arr, testSample)\n",
    "\n",
    "\n",
    "    # imgProd_max_index = set(list(imgProd_max_index[1:].astype(int)))\n",
    "    # imgProd_max_index_normal = set(list(imgProd_max_index_normal[1:].astype(int)))\n",
    "    # imgProd_max_index_fft = set(list(imgProd_max_index_fft[1:].astype(int)))\n",
    "    #imgProd_max_pindex = set(list(imgProd_max_pindex[1:]))\n",
    "    # imgProd_max_index_normal = imgProd_max_index_normal[1:]\n",
    "    imgProd_max_pindex = set(imgProd_max_pindex[1:])\n",
    "\n",
    "    # ind_arr = set(ind_arr)\n",
    "    ind_arr_2 = set(list(img_arr_2))\n",
    "    print(len(ind_arr_2))\n",
    "    # ind_arr_3 = set(ind_arr_3)\n",
    "    # ind_arr_4 = set(ind_arr_4)\n",
    "\n",
    "    # problem is branch isnt even visited.... for some img...\n",
    "\n",
    "    # if (imgProd_max_index != imgProd_max_index_normal or imgProd_max_index_normal != imgProd_max_index_fft or imgProd_max_index_fft != imgProd_max_pindex or imgProd_max_pindex != ind_arr \n",
    "    #     or ind_arr != ind_arr_2 or ind_arr_2 != ind_arr_3):\n",
    "    # if (ind_arr != ind_arr_2 or ind_arr_2 != ind_arr_3 or ind_arr_3 != ind_arr_4):\n",
    "    # if (ind_arr != ind_arr_2 or ind_arr_2 != ind_arr_3):\n",
    "    if (ind_arr_2 != imgProd_max_pindex):\n",
    "        ind_arr_2 = list(ind_arr_2)\n",
    "        \n",
    "        # print(f\"ncc rocket fft: {imgProd_max_index}\")\n",
    "        # imgProd_max_index_normal = list(imgProd_max_index_normal)\n",
    "        # print(f\"ncc normal: {imgProd_max_index_normal}\")\n",
    "        # print(f\"ncc fft: {imgProd_max_index_fft}\")\n",
    "        imgProd_max_pindex = list(imgProd_max_pindex)\n",
    "        print(f\"ncc parallel rocket fft: {imgProd_max_pindex}\")\n",
    "        print(f\"mtree normal: {ind_arr_2}\")\n",
    "        # print(f\"mtree normal:{ind_arr_2}\")\n",
    "        # print(f\"mtree w fft: {ind_arr_3}\")\n",
    "        for j in ind_arr_2:\n",
    "            for i in range(len(imgProd_max_pindex)):\n",
    "                #print(metrics.distance(testSample[j], testSample[imgProd_max_index_normal[i]]))\n",
    "                print(f\"DISTANCE TO IMG from index {j}: {metrics.distance(testSample[j], unseen_image)}\")\n",
    "                print(f\"DISTANCE TO IMG W INDEX from index {j}: {metrics.dist_with_index((testSample[j], j), (unseen_image, -1))}\")\n",
    "                print(f\"DISTANCE TO IMG TEST from index {i}: {metrics.distance(testSample[imgProd_max_pindex[i]], unseen_image)}\")\n",
    "        # for i in range(len(img_arr)):\n",
    "        #     print(metrics.distance(img_arr[i], ))\n",
    "\n",
    "        # print(f\"mtree w mst normal: {ind_arr_4}\")\n",
    "\n",
    "\n",
    "# print(unseen_img_parr)\n",
    "# print(unseen_img_arr)\n",
    "# print(unseen_img_arr_fft)\n",
    "# print(unseen_img_arr_normal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7b8613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(math.acos(0.9999998807907104) / (math.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "688688ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.294783823075704\n"
     ]
    }
   ],
   "source": [
    "k=3\n",
    "runs = 100\n",
    "ttime = 0\n",
    "image_size = 100\n",
    "sample_size = 500\n",
    "\n",
    "\n",
    "data = get_data_MStar(image_size)\n",
    "\n",
    "sample_indices = random.sample(range(len(data)), sample_size)\n",
    "sampled_test_data = Subset(data, sample_indices)\n",
    "\n",
    "testSample = [item[0] for item in sampled_test_data]\n",
    "testSampleIndexed = []\n",
    "for i in range(len(testSample)):\n",
    "    testSampleIndexed.append((testSample[i], i))\n",
    "\n",
    "index1 = np.random.choice(sample_indices)\n",
    "unseen_image = data[index1][0]\n",
    "unseen_image_indexed = [unseen_image, index1]\n",
    "\n",
    "start = time.perf_counter()\n",
    "normal_tree = getMTree(testSampleIndexed, 3, d=metrics.dist_fft_numba_indexed)\n",
    "end = time.perf_counter()\n",
    "print(end - start)\n",
    "# print(len(normal_tree))\n",
    "img_arr_2 = getKNearestNeighbours(normal_tree, unseen_image_indexed, k=3)\n",
    "img_arr_2 = [item[1] for item in img_arr_2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "fe5dcfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 200\n",
    "sample_size = 100000\n",
    "\n",
    "data = get_data_SARDet_100k(image_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88c65ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116598\n"
     ]
    }
   ],
   "source": [
    "sample_indices = random.sample(range(len(data)), sample_size)\n",
    "sampled_test_data = Subset(data, sample_indices)\n",
    "\n",
    "testSample = [item[0] for item in sampled_test_data]\n",
    "# testSampleIndexed = []\n",
    "# for i in range(len(testSample)):\n",
    "#     testSampleIndexed.append((testSample[i], i))\n",
    "index1 = np.random.choice(sample_indices)\n",
    "# index1 = np.random.randint(len(testSample))\n",
    "# print(f\"UNSEEN IMAGE INDEX: {index1}\")\n",
    "#index1 = np.random.randint(len(data))\n",
    "unseen_image = data[index1][0]\n",
    "# unseen_image = testSample[index1]\n",
    "# unseen_image_indexed = [unseen_image, index1]\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aa2b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "parallel time: 3.214570826967247\n",
      "[ 3434 25756 95164 21632 93036 68541 65686 74288]\n",
      "[ 3434 25756 95164 21632 93036 68541 65686 74288]\n"
     ]
    }
   ],
   "source": [
    "arr = np.ones(len(testSample))\n",
    "\n",
    "k=7\n",
    "print(len(testSample))\n",
    "\n",
    "start = time.perf_counter()\n",
    "unseen_img_arr = linear_ncc_search(testSample, unseen_image, arr)\n",
    "imgProd_max_index = np.argpartition(unseen_img_arr, -(k+1))[-(k+1):]\n",
    "end = time.perf_counter()\n",
    "print(f\"fft time: {end - start}\")\n",
    "\n",
    "start = time.perf_counter()\n",
    "unseen_img_parr = linear_ncc_psearch(testSample, unseen_image, arr)\n",
    "imgProd_max_pindex = np.argpartition(unseen_img_parr, -(k+1))[-(k+1):]\n",
    "end = time.perf_counter()\n",
    "print(f\"parallel time: {end-start}\")\n",
    "\n",
    "print(imgProd_max_index)\n",
    "print(imgProd_max_pindex)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ff0d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cupy-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
